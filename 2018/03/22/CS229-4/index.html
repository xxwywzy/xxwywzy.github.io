<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/resources/favicon/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/resources/favicon/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/resources/favicon/favicon.png">
  <link rel="mask-icon" href="/resources/favicon/favicon.png" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xxwywzy.github.io","root":"/","images":"/resources/img/","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"livere","storage":true,"lazyload":false,"nav":null,"activeClass":"livere"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。">
<meta property="og:type" content="article">
<meta property="og:title" content="CS229 学习笔记之四：生成学习算法">
<meta property="og:url" content="https://xxwywzy.github.io/2018/03/22/CS229-4/">
<meta property="og:site_name" content="口仆">
<meta property="og:description" content="本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-042015.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-042613.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-052112.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-053030.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-053331.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-074430.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-081704.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-085604.png">
<meta property="article:published_time" content="2018-03-22T01:45:45.000Z">
<meta property="article:modified_time" content="2023-08-15T06:20:51.000Z">
<meta property="article:author" content="Zheyu Wang">
<meta property="article:tag" content="CS229">
<meta property="article:tag" content="生成学习算法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://media.zjubiomedit.com/2019-05-11-042015.png">


<link rel="canonical" href="https://xxwywzy.github.io/2018/03/22/CS229-4/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://xxwywzy.github.io/2018/03/22/CS229-4/","path":"2018/03/22/CS229-4/","title":"CS229 学习笔记之四：生成学习算法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CS229 学习笔记之四：生成学习算法 | 口仆</title>
  











<link rel="stylesheet" href="/resources/fonts/longcang/longcang-regular.css" >
<link rel="stylesheet" href="/resources/fonts/lxgw/lxgwwenkailite-regular.css" >
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">口仆</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Long may the sunshine</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-culture"><a href="/culture/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>MEME</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">算法概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">高斯判别分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%85%83%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="nav-number">2.1.</span> <span class="nav-text">多元正态分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.2.</span> <span class="nav-text">高斯判别分析模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%E4%B8%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">2.3.</span> <span class="nav-text">高斯判别分析与逻辑回归</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">朴素贝叶斯算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0-1"><span class="nav-number">3.1.</span> <span class="nav-text">算法概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91"><span class="nav-number">3.2.</span> <span class="nav-text">拉普拉斯平滑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.</span> <span class="nav-text">文本分类的事件模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE"><span class="nav-number">4.</span> <span class="nav-text">思维导图</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zheyu Wang"
      src="/resources/favicon/avatar.png">
  <p class="site-author-name" itemprop="name">Zheyu Wang</p>
  <div class="site-description" itemprop="description">相信过程</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">85</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/xxwywzy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/xxwywzy" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/xxwywzy" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/xxwywzy" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xxwywzy.github.io/2018/03/22/CS229-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/resources/favicon/avatar.png">
      <meta itemprop="name" content="Zheyu Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="口仆">
      <meta itemprop="description" content="相信过程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CS229 学习笔记之四：生成学习算法 | 口仆">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS229 学习笔记之四：生成学习算法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-03-22 09:45:45" itemprop="dateCreated datePublished" datetime="2018-03-22T09:45:45+08:00">2018-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">课程笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><div class="note info"><p>本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。</p>
</div>
<span id="more"></span>
<h1 id="算法概述">算法概述</h1>
<p>到目前为止，我们讨论的学习算法都是直接对 <span class="math inline">\(p(y\mid x;\theta)\)</span> 建模，即对于给定的 <span class="math inline">\(x\)</span>，<span class="math inline">\(y\)</span> 的条件分布。这里我们将讨论一种不同类型的学习算法。</p>
<p>学习算法可以分为两种，一种是尝试去直接学习得到 <span class="math inline">\(p(y \mid x)\)</span>（例如逻辑回归），或者尝试去学习直接将输入映射到0或1的方法（例如感知器算法），这种算法被称为<strong>判别学习算法</strong>；而另外一种学习算法被称为<strong>生成学习算法</strong>，这种算法会尝试对 <span class="math inline">\(p(x\mid y)\)</span> 以及 <span class="math inline">\(p(y)\)</span> 建模。</p>
<p>当我们为 <span class="math inline">\(p(y)\)</span> (被称为<strong>class priors</strong>) 和 <span class="math inline">\(p(x\mid y)\)</span> 建模后，我们的算法会使用<strong>贝叶斯定理</strong>来计算给定 <span class="math inline">\(x\)</span> 后 <span class="math inline">\(y\)</span> 的<strong>后验概率</strong>： <span class="math display">\[
p(y\mid x) = \frac {p(x\mid y)p(y)} {p(x)}
\]</span></p>
<p>其中分母可以通过 <span class="math inline">\(p(x) = p(x|y=1)p(y=1) + p(x|y=0)p(y=0)\)</span> 得到（针对二分类）。</p>
<p>对于分类问题，我们需要对每种 <span class="math inline">\(y\)</span> 的情况分别进行建模。当有一个新的 <span class="math inline">\(x\)</span> 时，计算每个 <span class="math inline">\(y\)</span> 的后验概率，并取概率最大的那个 <span class="math inline">\(y\)</span> 作为预测输出。</p>
<p>由于只需要比较大小，而<span class="math inline">\(p(x)\)</span> 对于大家都是一样的，所以可以忽略分母，得到下式： <span class="math display">\[
\begin{align*}
\arg\max_{y} p(y|x) &amp;= \arg\max_{y} \frac {p(x| y)p(y)} {p(x)}\\ &amp;= \arg\max_{y}  p(x| y)p(y) 
\end{align*}
\]</span></p>
<h1 id="高斯判别分析">高斯判别分析</h1>
<p>我们学习的第一个生成学习算法叫<strong>高斯判别分析</strong>（GDA）。在这个模型中，我们会假设 <span class="math inline">\(p(x|y)\)</span> 属于<strong>多元正态分布</strong>。在介绍 GDA 之前，首先简单介绍一下多元正态分布的属性。</p>
<h2 id="多元正态分布">多元正态分布</h2>
<p>多元正态分布是在 n 维空间中的，其参数有：</p>
<ul>
<li><strong>均值向量</strong>：<span class="math inline">\(\mu \in \mathbb{R}^{n}\)</span></li>
<li><strong>协方差矩阵</strong>：<span class="math inline">\(\Sigma \in \mathbb{R}^{n \times n}\)</span>，<span class="math inline">\(\Sigma \ge 0\)</span> 对称且为半正定（所有特征值均不小于零）</li>
</ul>
<p>我们将分布记作 <span class="math inline">\({\cal N} (\mu,\Sigma)\)</span> ，其<strong>概率密度</strong>公式为： <span class="math display">\[
p(x;\mu, \Sigma) = \frac {1} {(2\pi)^{n/2} |\Sigma |^{1/2}} \exp \left(- \frac{1} {2} (x-\mu)^{T}\Sigma^{-1}(x-\mu)\right)
\]</span></p>
<p>其中 <span class="math inline">\(|\Sigma|\)</span> 表示 <span class="math inline">\(\Sigma\)</span> 的行列式。对于一个属于多元正态分布 <span class="math inline">\({\cal N} (\mu,\Sigma)\)</span> 的随机变量 <span class="math inline">\(X\)</span>，根据期望与方差的计算公式可以得到： <span class="math display">\[
\begin{align*}
E[X] &amp;= \int_x xp(x; \mu, \Sigma)dx \\
&amp;=\mu \\
Cov(X) &amp;= E[(X - E[X])(X - E[X])^T] \\
&amp;= \Sigma
\end{align*}
\]</span> 下面给出一些二元高斯分布的概率密度图像：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-042015.png" width=60%></p>
<p>左边的图显示的分布均值为 <span class="math inline">\(0\)</span>（<span class="math inline">\(2\times1\)</span>的向量），协方差矩阵为 <span class="math inline">\(I\)</span> （<span class="math inline">\(2 \times 2\)</span>的单位矩阵）。这样的正态分布又被称为<strong>标准正态分布</strong>；中间的图显示的分布均值为 <span class="math inline">\(0\)</span> 且 <span class="math inline">\(\Sigma = 0.6 I\)</span>；右边的图显示的分布 <span class="math inline">\(\Sigma = 2 I\)</span>。可以看到随着 <span class="math inline">\(\Sigma\)</span> 的变大，分布变得越来越“展开”，看起来就像变得越来越“扁”。</p>
<p>让我们来看看更多的例子：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-042613.png" width=60%></p>
<p>上图表示的分布均值均为 <span class="math inline">\(0\)</span>，对应的协方差矩阵为： <span class="math display">\[
\Sigma =\left[ \begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
1 &amp; 0.5 \\
0.5 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
1 &amp; 0.8 \\
0.8 &amp; 1 
\end{array} 
\right ]
\]</span> 左边的图就是标准正态分布，而可以看到随着非对角线上数值的增大，分布在45度方向上压缩的幅度越大，通过下面的轮廓图可以更清楚地展现这个特点：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-052112.png" width=60%></p>
<p>下面是另一组例子:</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-053030.png" width=60%></p>
<p>上图对应的协方差为： <span class="math display">\[
\Sigma =\left[ \begin{array}{cc}
1 &amp; -0.5 \\
-0.5 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
1 &amp; -0.8 \\
-0.8 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
3 &amp; 0.8 \\
0.8 &amp; 1 
\end{array} 
\right ]
\]</span> 从左图和中图可以看到，随着元素值的减小（绝对值变大），分布在相反的方向上“压缩”得越明显；而在右图中我们改变了对角线上的元素值，分布变得更趋近于椭圆。</p>
<p>在最后一组例子中，令 <span class="math inline">\(\Sigma = I\)</span>，通过改变 <span class="math inline">\(\mu\)</span> ，我们可以移动分布的中心：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-053331.png" width=60%></p>
<p>总而言之，多元正态分布与正态分布一样是<strong>钟型曲线</strong>，两个参数会影响分布的位置与形状： + <span class="math inline">\(\mu\)</span> 会影响分布的位置（平移） + <span class="math inline">\(\Sigma\)</span> 会影响分布的形状</p>
<h2 id="高斯判别分析模型">高斯判别分析模型</h2>
<p>对于一个分类问题，输入变量 <span class="math inline">\(x\)</span> 是连续随机变量，我们可以使用高斯判别分析（GDA）模型，对 <span class="math inline">\(p(x| y)\)</span> 使用多元正态分布建模，模型如下： <span class="math display">\[
\begin{align*}
y &amp;\sim \text{Bernoulli} (\phi) \\
x| y=0 &amp;\sim \cal{N} (\mu_0, \Sigma) \\
x| y=1 &amp;\sim \cal{N} (\mu_1, \Sigma) \\
\end{align*}
\]</span> 其概率密度如下： <span class="math display">\[
\begin{align*}
p(y) &amp;= \phi^y(1-\phi)^{1-y} \\
p(x| y=0) &amp;= \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}\exp\left(-\frac 1 2 (x-\mu_0)^T\Sigma^{-1}(x-\mu_0)\right) \\
p(x| y=1) &amp;= \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}\exp\left(-\frac 1 2 (x-\mu_1)^T\Sigma^{-1}(x-\mu_1)\right) 
\end{align*}
\]</span></p>
<p>这里模型的参数包括 <span class="math inline">\(\phi, \Sigma, \mu_0, \mu_1\)</span>，注意两个分布<strong>共享同一个协方差矩阵</strong>。</p>
<p>数据的对数似然函数如下： <span class="math display">\[
\begin{align*}
\ell(\phi,\mu_0, \mu_1,\Sigma) &amp;= \log \prod_{i=1}^mp(x^{(i)},y^{(i)};\phi,\mu_0\mu_1,\Sigma) \\
&amp;=  \log \prod_{i=1}^mp(x^{(i)} | y^{(i)};\mu_0,\mu_1,\Sigma) p(y^{(i)};\phi)
\end{align*}
\]</span></p>
<p>通过最大化 <span class="math inline">\(\ell\)</span>，得到参数的极大似然估计为： <span class="math display">\[
\begin{align*}
\phi &amp;= \frac 1 m \sum_{i=1}^m 1\{y^{(i)} =  1\} \\
\mu_0 &amp;= \frac{\sum_{i=1}^m 1\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^m 1\{y^{(i)}=0\}} \\
\mu_1 &amp;= \frac{\sum_{i=1}^m 1\{y^{(i)}=1\}x^{(i)}}{\sum_{i=1}^m 1\{y^{(i)}=1\}} \\
\Sigma &amp;= \frac 1 m \sum_{i=1}^m (x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T
\end{align*}
\]</span> 用图形来表示，该算法可以表示为下图：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-074430.png" width=35%></p>
<p>图中展示的是训练集，求得的高斯分布拟合至数据中，将数据分为了两类。注意两个高斯分布的形状相同，因为它们共享同一个协方差矩阵，但是它们的均值不同。</p>
<p>图中的直线表示决策边界：<span class="math inline">\(p(y=1|x) = 0.5\)</span>，在该边界的一侧，我们预测 <span class="math inline">\(y=1\)</span> 是最可能的输出，在另一侧，则预测 <span class="math inline">\(y=0\)</span>。</p>
<h2 id="高斯判别分析与逻辑回归">高斯判别分析与逻辑回归</h2>
<p>高斯判别分析与逻辑回归之间有着有趣的关系。如果我们将 <span class="math inline">\(p(y=1 |x; \phi,\mu_0,\mu_1, \Sigma)\)</span>表示为 <span class="math inline">\(x\)</span> 的函数，可以得到：</p>
<p><span class="math display">\[
p(y=1 | x;\phi,\Sigma,\mu_0,\mu_1) = \frac 1 {1+\exp(-\theta^T x)}
\]</span></p>
<p>这与逻辑回归的形式完全相同。但一般来说，对于相同的数据集两种算法会给出不同的边界，究竟哪一个更好呢？</p>
<p>一个有趣的结论是：</p>
<blockquote>
<p>如果 <span class="math inline">\(p(x| y)\)</span> 属于多元高斯分布（共享 <span class="math inline">\(\Sigma\)</span>），那么 <span class="math inline">\(p(y| x)\)</span> 一定是逻辑函数，反之不成立。</p>
</blockquote>
<p>上述结论表明高斯判别分析相较于逻辑回归提出了<strong>更强</strong>的假设。如果这些假设都是正确的，那么高斯判别分析得到的结果会更好，是更好的模型。特别地，当 <span class="math inline">\(p(x|y)\)</span> 属于多元高斯分布（共享 <span class="math inline">\(\Sigma\)</span>），GDA 是<strong>渐近有效</strong>的。这说明在数据量比较有限的情况下，没有算法能比 GDA 的表现更好。因此，在这种情况下，GDA 相比逻辑回归是一个更好的算法，即使对于较少的训练集，也可以取得更好的效果。</p>
<p>相反，因为进行了更弱的假设，所以逻辑回归有更好的<strong>鲁棒性</strong>，对于错误的模型假设不那么敏感。有很多不同的假设会导致 <span class="math inline">\(p(y| x)\)</span> 是逻辑函数的形式，比如泊松分布。但是如果我们对于这样的数据使用 GDA，那么结果会变得不可预测。</p>
<p>总结一下，GDA 进行了更强的模型假设并且数据有效性更高（需要更少的数据来学习），但其前提条件是模型假设正确或近似正确；逻辑回归进行较弱的假设，对于模型假设偏离的鲁棒性更好。如果数据集实际上不是高斯分布，那么在数据有限的情况下，逻辑回归一般会表现得比 GDA 更好。因此，实际中使用逻辑回归的情况比 GDA 多得多。</p>
<h1 id="朴素贝叶斯算法">朴素贝叶斯算法</h1>
<h2 id="算法概述-1">算法概述</h2>
<p>在高斯判别分析中，输入是连续变量。现在我们要谈谈一个不同的生成学习算法，其中 <span class="math inline">\(x\)</span> 是<strong>离散变量</strong>。</p>
<p>让我们以识别垃圾邮件为例，这类问题被称为<strong>文本分类</strong>问题。假设我们有一个训练集（已经标记好了是否为垃圾邮件的邮件集合），我们首先需要构建表示一封邮件的特征向量。</p>
<p>我们通过如下方式表示特征向量：其长度为词表的长度，词表为所有可能出现的词的集合，一般通过训练集生成。如果这封邮件包含了第 i 个词，<span class="math inline">\(x_i = 1\)</span>，否则 <span class="math inline">\(x_i = 0\)</span>。下图为一个简单的例子： <span class="math display">\[
x=\left[\begin{array}{c}{1} \\ {0} \\ {0} \\ {\vdots} \\ {1} \\ {\vdots} \\ {0}\end{array}\right] \quad \begin{array}{l}\text{a} \\ {\text {aardvark }} \\ {\text {aardwolf }} \\ {\vdots} \\ {\text {buy }} \\ {\vdots} \\ {\text {zygmurgy }}\end{array}
\]</span> 选择好特征向量后，我们需要来构建生成模型。但考虑到 <span class="math inline">\(x\)</span> 是一个高维向量，因此如果直接对 <span class="math inline">\(p(x|y)\)</span> 建模，那么会得到一个参数向量的维数极高的多项分布，使计算过于复杂。</p>
<p>因此，我们需要做一个强力的假设，假设给定 <span class="math inline">\(y\)</span> 时， 每一个 $x_i $ 是条件独立的。这个假设被称为<strong>朴素贝叶斯假设</strong>，其引出的算法被称为<strong>朴素贝叶斯分类器</strong>。注意是条件独立而不是独立，即仅在给定 <span class="math inline">\(y\)</span> 的情况下独立。</p>
<p>现在我们有（以50000维度为例）： <span class="math display">\[
\begin{align*}
p(x_1,\ldots,x_{50000}\mid y) &amp;=  
p(x_1 | y) p(x_2 | y,x_1)p(x_3 | y,x_1,x_2)\cdots p(x_{50000} | y,x_1, \ldots, x_{49999})\\
&amp;=p(x_1 | y)p(x_2 | y) p(x_3 | y)\cdot p(x_{50000} | y)\\
&amp;= \prod_{j=1}^np(x_j| y)
\end{align*}
\]</span></p>
<p>第一个等式来自于概率的基本性质；第二个等式则使用了朴素贝叶斯假设。即使这个假设在现实中不一定成立，但其实际的效果还是不错的。</p>
<p>模型包含了以下三个参数： <span class="math display">\[
\begin{align*}
\phi_{i|y=1} &amp;= p(x_i = 1 | y=1) \\
\phi_{i|y=0} &amp;= p(x_i = 1 | y=0) \\
\phi_y &amp;= p(y = 1 )
\end{align*}
\]</span> 和之前一样，给定一个训练集 <span class="math inline">\(\{(x^{(i)},y^{(i)}); i=1,\dots,m\}\)</span>，我们可以写出如下的联合似然函数</p>
<p><span class="math display">\[
\mathcal{L} (\phi_y,\phi_{i|y=0},\phi_{i|y=1}) = \prod_{i=1}^m p(x^{(i)},y^{(i)})
\]</span></p>
<p>对这个联合似然函数进行最大似然分析，得到的参数值如下： <span class="math display">\[
\begin{align*}
\phi_{j|y=1} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=1\}}{\sum_{i=1}^m 1\{y^{(i)}=1\}}\\
\phi_{j|y=0} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=0\}}{\sum_{i=1}^m 1\{y^{(i)}=0\}} \\
\phi_y &amp;= \frac {\sum_{i=1}^m 1\{y^{(i)} = 1\}}{m}
\end{align*}
\]</span></p>
<p>这些结果的得出是很自然的，从概率的角度也可以很好地解释。得到了这些参数之后，为了对一个新的输入 <span class="math inline">\(x\)</span> 进行预测，我们可以计算： <span class="math display">\[
\begin{align*}
p(y=1 | x) &amp;= \frac{p(x| y=1)p(y=1)}{p(x)} \\
&amp;= \frac {(\prod_{i=1}^n p(x_i | y=1))p(y=1)}{(\prod_{i=1}^n p(x_i | y=1))p(y=1)+(\prod_{i=1}^n p(x_i | y=0))p(y=0)}
\end{align*}
\]</span></p>
<p>然后选择具有更高后验概率的类作为输出。这里的 <span class="math inline">\(n\)</span> 指字典的维数，需要先把 <span class="math inline">\(x\)</span> 转换为统一长度的向量。</p>
<p>在之前的例子中，输入的每一维特征都是是二元的，其对应的分布是伯努利分布。而当特征是多元时，其对应的分布应该用<strong>多项式分布</strong>建模。</p>
<p>实际上，即便一些原始的输入数据是连续值，我们可以通过一个映射表将连续值映射为离散值，然后运用朴素贝叶斯方法进行建模：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-081704.png" width=60%></p>
<p>当原始连续值的数据不能很好的用多元正态分布进行建模时，将其离散化再使用朴素贝叶斯建模往往会取得更好的效果。</p>
<h2 id="拉普拉斯平滑">拉普拉斯平滑</h2>
<p>朴素贝叶斯算法有很多的应用，但是其当前的形式仍存在一个问题：在垃圾邮件分类问题中，如果词典中存在一个词，而这个词在训练集中从未出现过时，其最大似然分析得出的参数 <span class="math inline">\(\phi_{35000|y}\)</span> 将会是： <span class="math display">\[
\begin{align*}
\phi_{35000|y=1} &amp;= \frac{\sum_{i=1}^m 1\{x_{35000}^{(i)}=1 \wedge y^{(i)}=1\}}{\sum_{i=1}^m 1\{y^{(i)}=1\}} =0 \\
\phi_{35000|y=0} &amp;= \frac{\sum_{i=1}^m 1\{x_{35000}^{(i)}=1 \wedge y^{(i)}=0\}}{\sum_{i=1}^m 1\{y^{(i)}=0\}} = 0 \\
\end{align*}
\]</span></p>
<p>因此，当我们尝试去预测含有该词的邮件是否为垃圾邮件时，后验概率的计算结果将变为： <span class="math display">\[
\begin{align*}
p(y=1 | x) &amp;= \frac {(\prod_{i=1}^n p(x_i | y=1))p(y=1)}{(\prod_{i=1}^n p(x_i | y=1))p(y=1)+(\prod_{i=1}^n p(x_i | y=0))p(y=0)} \\
&amp;= \frac 0 0
\end{align*}
\]</span></p>
<p>这会导致我们无法进行预测。更一般的来看，如果你在有限的训练集上没有看到过某个事件，就认为其发生的概率为 0，这在统计学上是不合理的。</p>
<p>现在假设我们要分析一个多项式随机变量 <span class="math inline">\(z\)</span> 的均值，取值为 <span class="math inline">\(\{1,\dots,k\}\)</span>，我们可以分析 <span class="math inline">\(\phi_j=p(z=j)\)</span>。给定一个独立的观察集 <span class="math inline">\(\{z^{(1)},\dots,z^{(m)}\}\)</span>，最大似然估计的结果为：</p>
<p><span class="math display">\[
\phi_j = \frac {\sum_{i=1}^m 1\{z^{(i)}=j\}}{m}
\]</span></p>
<p>如果我们用这个公式来进行最大似然估计，那么有一些 <span class="math inline">\(\phi_j\)</span> 的值可能为0（如果未在观察集中出现）。为了避免这个问题，我们可以使用<strong>拉普拉斯平滑</strong>，其形式为： <span class="math display">\[
\phi_j = \frac {\sum_{i=1}^m 1\{z^{(i)}=j\}+1}{m+k}
\]</span></p>
<p>分子加 <span class="math inline">\(1\)</span>，分母加 <span class="math inline">\(k\)</span>，这样可以保证 <span class="math inline">\(\sum_{j=1}^m \phi_j=1\)</span>（概率之和为1）。同时保证了对所有的取值， <span class="math inline">\(\phi_j \neq 0\)</span>，从而解决了之前的问题。实验证明，在大部分情况下，拉普拉斯平滑可以给出一个最优的估计。</p>
<p>对于朴素贝叶斯分类器，使用拉普拉斯平滑，可以得到如下公式： <span class="math display">\[
\begin{align*}
\phi_{j|y=1} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=1\}+1}{\sum_{i=1}^m 1\{y^{(i)}=1\}+2}\\
\phi_{j|y=0} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=0\}+1}{\sum_{i=1}^m 1\{y^{(i)}=0\}+2} 
\end{align*}
\]</span></p>
<p>因为 <span class="math inline">\(x\)</span> 的取值有两种，所以分子加 <span class="math inline">\(1\)</span>，分母加 <span class="math inline">\(2\)</span>。在实际应用中，一般不需要对 <span class="math inline">\(\phi_y\)</span> 进行拉普拉斯平滑。</p>
<h2 id="文本分类的事件模型">文本分类的事件模型</h2>
<p>让我们再探讨一个专门用于文本分类的模型来结束生成学习算法。虽然朴素贝叶斯对许多分类问题有很好的效果，但是对于文本分类，还存在着一个效果更棒的相关模型。</p>
<p>在文本分类领域，之前我们使用的朴素贝叶斯模型被称为<strong>多元伯努利事件模型</strong>。现在我们将使用一个不同的模型，叫作<strong>多项式事件模型</strong>。我们将使用与之前不同的方式来表示一封邮件：</p>
<p>令 <span class="math inline">\(x_i\)</span> 表示邮件中的第 <span class="math inline">\(i\)</span> 个词语，则其取值范围为 <span class="math inline">\(\{1,\ldots,|V|\}\)</span>，<span class="math inline">\(|V|\)</span> 是词表（词典）的大小。一封含有 <span class="math inline">\(n\)</span> 个词语的邮件现在将被表示为一个长度为 <span class="math inline">\(n\)</span> 的向量 <span class="math inline">\((x_1,x_2,\ldots,x_n)\)</span> ，注意 <span class="math inline">\(n\)</span> 会随邮件的不同而变化。</p>
<p>该模型的参数为： <span class="math display">\[
\begin{align*}
\phi_{i|y=1} &amp;= p(x_j = i | y=1)\\
\phi_{i|y=0} &amp;= p(x_j = i | y=0)\\
\phi_y &amp;= p(y)
\end{align*}
\]</span></p>
<p>我们假设 $p(x_j| y) $ 对所有的 <span class="math inline">\(j\)</span>（邮件中词语的位置）都是一样的。</p>
<p>如果给定一个训练集 <span class="math inline">\(\{(x^{(i)},y^{(i)}); i=1,\ldots,m\}\)</span>，其中 <span class="math inline">\(x^{(i)} = (x_1^{(i)},x_2^{(i)},\dots,x_{n_i}^{(i)})\)</span>。这里 <span class="math inline">\(n_i\)</span> 表示第 <span class="math inline">\(i\)</span> 个训练样本的词数，那么数据的似然函数可以表示为：</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{L} (\phi_y,\phi_{i|y=0},\phi_{i|y=1}) &amp;= \prod_{i=1}^m p(x^{(i)},y^{(i)}) \\
&amp;= \prod_{i=1}^m \left(\prod_{j=1}^{n_i} p(x_j^{(i)}\mid y;\phi_{i|y=0},\phi_{i|y=1}) \right) p(y^{(i)};\phi_y)
\end{align*}
\]</span> 最大似然估计得出的结果如下： <span class="math display">\[
\begin{align*}
\phi_{k|y=1} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i}1\{x_j^{(i)}=k \wedge y^{(i)}=1\}}{\sum_{i=1}^m 1\{y^{(i)}=1\}n_i} \\
\phi_{k|y=0} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i} 1\{x_j^{(i)}=k \wedge y^{(i)}=0\}}{\sum_{i=1}^m 1\{y^{(i)}=0\}n_i} \\
\phi_y &amp;= \frac {\sum_{i=1}^m 1\{y^{(i)} = 1\}}{m}
\end{align*}
\]</span></p>
<p>可以看到，这里在考虑字典中索引为 <span class="math inline">\(k\)</span> 的词时，会把在每个文本中出现的次数相加。所以该模型相比于之前的模型，不仅仅考虑是否出现，还考虑了<strong>出现的次数</strong>。</p>
<p>如果要应用拉普拉斯平滑，可以在分子加 <span class="math inline">\(1\)</span>，分母加 <span class="math inline">\(|V|\)</span>，得到： <span class="math display">\[
\begin{align*}
\phi_{k|y=1} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i}1\{x_j^{(i)}=k \wedge y^{(i)}=1\}+1}{\sum_{i=1}^m 1\{y^{(i)}=1\}n_i+|V|} \\
\phi_{k|y=0} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i} 1\{x_j^{(i)}=k \wedge y^{(i)}=0\}+1}{\sum_{i=1}^m 1\{y^{(i)}=0\}n_i+|V|} 
\end{align*}
\]</span> 虽然朴素贝叶斯不是最好的分类算法，但因为其易于实现，所以非常适合作为你的第一个尝试。</p>
<h1 id="思维导图">思维导图</h1>
<p><img src="http://media.zjubiomedit.com/2019-05-11-085604.png" width=100%></p>

    </div>

    
    
    

    <footer class="post-footer">




<div class="license">
  <div class="license-title">CS229 学习笔记之四：生成学习算法</div>
  <div class="license-link">
    <a href="https://xxwywzy.github.io/2018/03/22/CS229-4/">https://xxwywzy.github.io/2018/03/22/CS229-4/</a>
  </div>
  <div class="license-meta">
    <div class="license-meta-item">
      <div class="license-meta-title">本文作者</div>
      <div class="license-meta-text">
          Zheyu Wang
      </div>
    </div>
      <div class="license-meta-item">
        <div class="license-meta-title">发布于</div>
        <div class="license-meta-text">
          2018-03-22
        </div>
      </div>
      <div class="license-meta-item">
        <div class="license-meta-title">更新于</div>
        <div class="license-meta-text">
          2023-08-15
        </div>
      </div>
    <div class="license-meta-item">
      <div class="license-meta-title">许可协议</div>
      <div class="license-meta-text">
          <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank">CC BY-NC-SA 4.0</a>
      </div>
    </div>
  </div>
  <div class="license-statement">
      转载或引用本文时，请遵守上述许可协议，注明出处、不得用于商业用途！
  </div>
</div>
          <div class="post-tags">
              <a href="/tags/CS229/" rel="tag"># CS229</a>
              <a href="/tags/%E7%94%9F%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" rel="tag"># 生成学习算法</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/03/18/CS229-3/" rel="prev" title="CS229 学习笔记之三：广义线性模型">
                  <i class="fa fa-angle-left"></i> CS229 学习笔记之三：广义线性模型
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/04/01/CS229-5/" rel="next" title="CS229 学习笔记之五：支持向量机">
                  CS229 学习笔记之五：支持向量机 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="lv-container" data-id="city" data-uid="MTAyMC81ODgyNi8zNTI4OA=="></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Zheyu Wang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">332k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">18:26</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script src="/js/third-party/comments/livere.js"></script>



  <style>
    #taboola-livere { display: none;}
  </style>



<script type="text/javascript">
var linkLists = document.querySelectorAll(".link-list");

linkLists.forEach(function(linkList) {
  var listPath = linkList.getAttribute('json-src');
  var iconPath = linkList.getAttribute('icon-src');
  
  var xhr = new XMLHttpRequest();
  xhr.open('GET', listPath, true);
  xhr.onreadystatechange = function() {
    if (xhr.readyState === 4 && xhr.status === 200) {
      var data = JSON.parse(xhr.responseText);
      
      var li = "";
      linkList.innerHTML = '';

      for (var infoIndex = 0; infoIndex < data.length; infoIndex++) {
        var info = data[infoIndex];
        var labelWarn = info['warn'] ? '<span class="label warn">' + info['warn'] + '</span>' : '';
        var labelInfo = info['info'] ? '<span class="label info">' + info['info'] + '</span>' : '';

        li += '<div class="link-list-container">';
        li += '<img class="link-list-image" src="' + iconPath + info['logo'] + '">';
        li += '<p>' + info['title'] + labelInfo + labelWarn + '</p>';
        li += '<p>' + info['intro'] + '</p>';
        li += '<a href="' + info['url'] + '" rel="noopener" target="_blank" data-pjax-state=""></a>';
        li += '</div>';
      }
      
      linkList.innerHTML = li;
    }
  };
  xhr.send();
});
</script>


<script type="text/javascript">
var cultureList = document.querySelectorAll(".culture-list");
if (cultureList.length !== 0) {
  var j = -1;
  for (var i = 0; i < cultureList.length; i++) {
    const listPath = cultureList[i].getAttribute('json-src');
    const coverPath = cultureList[i].getAttribute('cover-src');
    
    var xhr = new XMLHttpRequest();
    xhr.open('GET', listPath, true);
    xhr.onreadystatechange = function () {
      if (xhr.readyState === 4 && xhr.status === 200) {
        j++;
        var data = JSON.parse(xhr.responseText);
        var li = "";
        
        cultureList[j].innerHTML = '';

        for (var infoIndex = 0; infoIndex < data.length; infoIndex++) {
          var info = data[infoIndex];
          
          var title = info['title'];
          if (info['link']) {
            title = '<a href="' + info['link'] + '">' + info['title'] + '</a>';
          }

          var author = info['author'] ? '<span class="author">' + info['author'] + '</span>' : '';

          var intro = info['intro'] ? info['intro'] : '';

          var star = '';
          if (info['score'] == null) {
            star = '';
          } else {
            var colorStar = '';
            var greyStar = '';
            var int = Math.floor(info['score']); //整数部分
            var fract = 0;
            if (info['score'] % 1 !== 0) {
              fract = 1;
            }
            for (var m = 0; m < int; m++) {
              colorStar += '★';
            }
            if (fract !== 0) {
              colorStar += '☆';
            }
            for (var m = 0; m < (5 - fract - int); m++) {
              greyStar += '☆';
            }
            if (info['score'] !== 5) {
              star = '<span class="star-score">' + colorStar + '<span class="grey-star">' + greyStar + '</span></span>';
            } else {
              star = '<span class="star-score">' + colorStar + '</span>';
            }
          }

          li += '<div class="media">';
          li += '<div class="media-cover" style="background-image:url(' + coverPath + info['cover'] + ')"></div>';
          li += '<div class="media-meta">';
          li += '<div class="media-meta-item title">' + title + '</div>';
          li += '<div class="media-meta-item">' + author + star + '</div>';
          li += '<div class="media-meta-item intro">' + intro + '</div>';
          li += '</div></div>';
        }
        
        cultureList[j].innerHTML = li;
      }
    };
    xhr.send();
  }
}
</script>




<script src="/resources/minigrid.min.js"></script>
<script type="text/javascript">
var album = document.querySelector(".album");
if (album) {
  // 相册列表 JSON 数据
  var imgDataPath = album.getAttribute('json-src');
  // 照片存储路径
  var imgPath = album.getAttribute('photo-src');
  // 最多显示数量
  var imgMaxNum = 50;
  // 获取窗口大小以决定图片宽度
  var windowWidth = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth;
  var imageWidth;

  if (windowWidth < 768) {
    imageWidth = 145; // 移动端图片宽度
  } else {
    imageWidth = 235;
  }

  // 腾讯云自定义样式 (数据万象外网流量需要付费)
  //var imgStyle = '!' + imageWidth + 'x';
  //var imgStyle = '!300x';

  // 生成相册
  var linkDataPath = imgDataPath;
  var photo = {
    page: 1,
    offset: imgMaxNum,
    init: function () {
      var that = this;
      var xhr = new XMLHttpRequest();
      xhr.open("GET", linkDataPath, true);
      xhr.onreadystatechange = function () {
        if (xhr.readyState === 4 && xhr.status === 200) {
          var data = JSON.parse(xhr.responseText);
          that.render(that.page, data);
        }
      };
      xhr.send();
    },
    render: function (page, data) {
      var begin = (page - 1) * this.offset;
      var end = page * this.offset;
      if (begin >= data.length) return;
      var imgNameWithPattern, imgName, imageSize, imageX, imageY, li = "";
      for (var i = begin; i < end && i < data.length; i++) {
        imgNameWithPattern = data[i].split(' ')[1];
        imgName = imgNameWithPattern.split('.')[0];
        imageSize = data[i].split(' ')[0];
        imageX = imageSize.split('.')[0];
        imageY = imageSize.split('.')[1];
        li += '<div class="card" style="width:' + imageWidth + 'px" >';
        li += '<div class="album-photo" style="height:'+ imageWidth * imageY / imageX + 'px">';
        li += '<a class="fancybox fancybox.image" href="' + imgPath + imgNameWithPattern + '" itemscope="" itemtype="http://schema.org/ImageObject" itemprop="url" data-fancybox="group" rel="group" data-caption="' + imgName + '" title="' +  imgName + '">';
        li += '<img data-src="' + imgPath + imgNameWithPattern + '" src="' + imgPath + imgNameWithPattern + '" alt="' +  imgName + '" data-loaded="true">';
        li += '</a>';
        li += '</div>';
        li += '</div>';
      }
      album.insertAdjacentHTML('beforeend', li);
      this.minigrid();
    },
    minigrid: function () {
      var grid = new Minigrid({
        container: '.album',
        item: '.card',
        gutter: 12
      });
      grid.mount();
      window.addEventListener('resize', function () {
        grid.mount();
      });
    }
  };
  photo.init();
}
</script>
</body>
</html>
