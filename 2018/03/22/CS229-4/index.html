<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"/>

<link rel="stylesheet" href="/css/main.css?v=7.0.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=7.0.0">


  <link rel="mask-icon" href="/images/favicon.png?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。">
<meta name="keywords" content="CS229,生成学习算法">
<meta property="og:type" content="article">
<meta property="og:title" content="CS229学习笔记之四：生成学习算法">
<meta property="og:url" content="https://xxwywzy.github.io/2018/03/22/CS229-4/index.html">
<meta property="og:site_name" content="xxwywzy&#39;s Blog">
<meta property="og:description" content="本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-042015.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-042613.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-052112.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-053030.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-053331.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-074430.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-080125.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-081704.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-05-11-085604.png">
<meta property="og:updated_time" content="2019-05-11T09:04:34.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CS229学习笔记之四：生成学习算法">
<meta name="twitter:description" content="本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。">
<meta name="twitter:image" content="http://media.zjubiomedit.com/2019-05-11-042015.png">






  <link rel="canonical" href="https://xxwywzy.github.io/2018/03/22/CS229-4/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>CS229学习笔记之四：生成学习算法 | xxwywzy's Blog</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a02b5462e7522b1ed191c4cea6b1d6e6";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">xxwywzy's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Long may the sunshine</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br/>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://xxwywzy.github.io/2018/03/22/CS229-4/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zheyu Wang"/>
      <meta itemprop="description" content="相信过程"/>
      <meta itemprop="image" content="/images/avatar.png"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xxwywzy's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CS229学习笔记之四：生成学习算法

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-22 09:45:45" itemprop="dateCreated datePublished" datetime="2018-03-22T09:45:45+08:00">2018-03-22</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <a href="/2018/03/22/CS229-4/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2018/03/22/CS229-4/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2018/03/22/CS229-4/" class="leancloud_visitors" data-flag-title="CS229学习笔记之四：生成学习算法">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <div class="note info">
            本篇博客为 CS229 学习笔记第四部分，主题是：生成学习算法。 
          </div>
<a id="more"></a>
<h1 id="算法概述">算法概述</h1>
<ul>
<li>到目前为止，我们讨论的学习算法都是直接对 <span class="math inline">\(p(y|x;\theta)\)</span> 建模，即对于给定的 <span class="math inline">\(x\)</span>，<span class="math inline">\(y\)</span> 的条件分布
<ul>
<li>这里我们将讨论一种不同类型的学习算法</li>
</ul></li>
<li>学习算法可以分为两种：
<ul>
<li><strong>判别学习算法</strong>：对 <span class="math inline">\(p (y|x)\)</span> 建模
<ul>
<li>或者学习直接将输入映射到 0 或 1 的方法</li>
</ul></li>
<li><strong>生成学习算法</strong>：对 <span class="math inline">\(p(x| y)\)</span>（以及 <span class="math inline">\(p(y)\)</span> ）建模</li>
</ul></li>
<li><p>当我们为 <span class="math inline">\(p(y)\)</span> (被称为 <strong>class priors</strong> ) 和 <span class="math inline">\(p(x| y)\)</span> 建模后，可以使用<strong>贝叶斯定理</strong>来计算给定 <span class="math inline">\(x\)</span> 后 <span class="math inline">\(y\)</span> 的后验概率： <span class="math display">\[
p(y|x) = \frac {p(x|y)p(y)} {p(x)}
\]</span></p>
<ul>
<li>分母可以通过 <span class="math inline">\(p(x) = p(x|y=1)p(y=1) + p(x|y=0)p(y=0)\)</span> 得到（针对二分类）</li>
</ul></li>
<li>对于分类问题，我们需要对每种 <span class="math inline">\(y\)</span> 的情况分别进行建模
<ul>
<li>当有一个新的 <span class="math inline">\(x\)</span> 时，计算每个 <span class="math inline">\(y\)</span> 的后验概率，并取概率最大的那个 <span class="math inline">\(y\)</span></li>
<li>而由于只需要比较大小，<span class="math inline">\(p(x)\)</span> 对于大家都是一样的，所以可以忽略分母，得到下式：</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\arg\max_{y} p(y|x) &amp;= \arg\max_{y} \frac {p(x| y)p(y)} {p(x)}\\ &amp;= \arg\max_{y}  p(x| y)p(y) 
\end{align*}
\]</span></p></li>
</ul>
<h1 id="高斯判别分析">高斯判别分析</h1>
<ul>
<li>我们学习的第一个生成学习算法叫<strong>高斯判别分析</strong>
<ul>
<li>在这个模型中，我们会假设 <span class="math inline">\(p(x|y)\)</span> 属于多元正态分布</li>
</ul></li>
<li>在介绍 GDA 之前，首先简单介绍一下多元正态分布的属性</li>
</ul>
<h2 id="多元正态分布">多元正态分布</h2>
<ul>
<li>多元正态分布是在 n 维空间中的，其参数有：
<ul>
<li><strong>均值向量</strong>：<span class="math inline">\(\mu \in \mathbb{R}^{n}\)</span></li>
<li><strong>协方差矩阵</strong>：<span class="math inline">\(\Sigma \in \mathbb{R}^{n \times n}\)</span>，<span class="math inline">\(\Sigma \ge 0\)</span> 对称且为半正定（所有特征值均不小于零）</li>
</ul></li>
<li><p>分布记作 <span class="math inline">\({\cal N} (\mu,\Sigma)\)</span> ，概率密度公式为： <span class="math display">\[
p(x;\mu, \Sigma) = \frac {1} {(2\pi)^{n/2} |\Sigma |^{1/2}} \exp \left(- \frac{1} {2} (x-\mu)^{T}\Sigma^{-1}(x-\mu)\right)
\]</span></p>
<ul>
<li><span class="math inline">\(|\Sigma|\)</span> 表示 <span class="math inline">\(\Sigma\)</span> 的行列式</li>
</ul></li>
<li><p>对于一个属于多元正态分布 <span class="math inline">\({\cal N} (\mu,\Sigma)\)</span> 的随机变量 <span class="math inline">\(X\)</span>，根据期望与方差的计算公式可以得到： <span class="math display">\[
\begin{align*}
E[X] &amp;= \int_x xp(x; \mu, \Sigma)dx \\
&amp;=\mu \\
Cov(X) &amp;= E[(X - E[X])(X - E[X])^T] \\
&amp;= \Sigma
\end{align*}
\]</span></p></li>
<li><p>下面给出一些二元高斯分布的概率密度图像：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-042015.png" width="60%"></p>
<ul>
<li>左边的图显示的分布均值为 <span class="math inline">\(0\)</span>（<span class="math inline">\(2\times1\)</span>的向量），协方差矩阵为 <span class="math inline">\(I\)</span> （<span class="math inline">\(2 \times 2\)</span>的单位矩阵）
<ul>
<li>这样的正态分布又被称为<strong>标准正态分布</strong></li>
</ul></li>
<li>中间的图显示的分布均值为 <span class="math inline">\(0\)</span> 且 <span class="math inline">\(\Sigma = 0.6 I\)</span></li>
<li>右边的图显示的分布 <span class="math inline">\(\Sigma = 2 I\)</span>
<ul>
<li>可以看到随着 <span class="math inline">\(\Sigma\)</span> 的变大，分布变得越来越“展开”，看起来就像变得越来越“扁”</li>
</ul></li>
</ul></li>
<li><p>让我们来看看更多的例子：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-042613.png" width="60%"></p>
<ul>
<li><p>上图表示的分布均值均为 <span class="math inline">\(0\)</span>，对应的协方差矩阵为： <span class="math display">\[
\Sigma =\left[ \begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
1 &amp; 0.5 \\
0.5 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
1 &amp; 0.8 \\
0.8 &amp; 1 
\end{array} 
\right ]
\]</span></p></li>
<li>左边的图就是标准正态分布，而可以看到随着非对角线上数值的增大，分布在45度方向上压缩的幅度越大
<ul>
<li>通过下面的轮廓图可以更清楚地展现这个特点：</li>
</ul>
<p><img src="http://media.zjubiomedit.com/2019-05-11-052112.png" width="60%"></p></li>
</ul></li>
<li><p>下面是另一组例子:</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-053030.png" width="60%"></p>
<ul>
<li><p>上图对应的协方差为： <span class="math display">\[
\Sigma =\left[ \begin{array}{cc}
1 &amp; -0.5 \\
-0.5 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
1 &amp; -0.8 \\
-0.8 &amp; 1 
\end{array} 
\right ]; 
\Sigma =\left[ \begin{array}{cc}
3 &amp; 0.8 \\
0.8 &amp; 1 
\end{array} 
\right ]
\]</span></p></li>
<li>从左图和中图可以看到，随着元素值的减小（绝对值变大），分布在相反的方向上“压缩”得越明显</li>
<li>在右图中我们改变了对角线上的元素值，分布变得更趋近于椭圆</li>
</ul></li>
<li><p>在最后一组例子中，令 <span class="math inline">\(\Sigma = I\)</span>，通过改变 <span class="math inline">\(\mu\)</span> ，我们可以移动分布的中心：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-053331.png" width="60%"></p></li>
<li>总而言之，多元正态分布与正态分布一样是钟型的曲线
<ul>
<li><span class="math inline">\(\mu\)</span> 会影响分布的位置（平移）</li>
<li><span class="math inline">\(\Sigma\)</span> 会影响分布的形状</li>
</ul></li>
</ul>
<h2 id="高斯判别分析模型">高斯判别分析模型</h2>
<ul>
<li><p>对于一个分类问题，输入变量 <span class="math inline">\(x\)</span> 是连续随机变量，我们可以使用高斯判别分析（GDA）模型，对 <span class="math inline">\(p(x| y)\)</span> 使用多元正态分布建模，模型如下： <span class="math display">\[
\begin{align*}
y &amp;\sim \text{Bernoulli} (\phi) \\
x| y=0 &amp;\sim \cal{N} (\mu_0, \Sigma) \\
x| y=1 &amp;\sim \cal{N} (\mu_1, \Sigma) \\
\end{align*}
\]</span></p></li>
<li><p>其分布如下： <span class="math display">\[
\begin{align*}
p(y) &amp;= \phi^y(1-\phi)^{1-y} \\
p(x| y=0) &amp;= \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}\exp\left(-\frac 1 2 (x-\mu_0)^T\Sigma^{-1}(x-\mu_0)\right) \\
p(x| y=1) &amp;= \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}\exp\left(-\frac 1 2 (x-\mu_1)^T\Sigma^{-1}(x-\mu_1)\right) 
\end{align*}
\]</span></p>
<ul>
<li>这里模型的参数包括 <span class="math inline">\(\phi, \Sigma, \mu_0, \mu_1\)</span>，注意两个分布共享同一个协方差矩阵</li>
</ul></li>
<li><p>数据的对数似然函数如下： <span class="math display">\[
\begin{align*}
\ell(\phi,\mu_0, \mu_1,\Sigma) &amp;= \log \prod_{i=1}^mp(x^{(i)},y^{(i)};\phi,\mu_0\mu_1,\Sigma) \\
&amp;=  \log \prod_{i=1}^mp(x^{(i)} | y^{(i)};\mu_0,\mu_1,\Sigma) p(y^{(i)};\phi)
\end{align*}
\]</span></p>
<ul>
<li>通过最大化 <span class="math inline">\(\ell\)</span>，得到参数的极大似然估计为： <span class="math display">\[
\begin{align*}
\phi &amp;= \frac 1 m \sum_{i=1}^m 1\{y^{(i)} =  1\} \\
\mu_0 &amp;= \frac{\sum_{i=1}^m 1\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^m 1\{y^{(i)}=0\}} \\
\mu_1 &amp;= \frac{\sum_{i=1}^m 1\{y^{(i)}=1\}x^{(i)}}{\sum_{i=1}^m 1\{y^{(i)}=1\}} \\
\Sigma &amp;= \frac 1 m \sum_{i=1}^m (x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T
\end{align*}
\]</span></li>
</ul></li>
<li><p>用图形来表示，该算法可以表示为下图：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-074430.png" width="35%"></p>
<ul>
<li>图中展示的是训练集，求得的高斯分布拟合至数据中，将数据分为了两类
<ul>
<li>注意两个高斯分布的形状与方向相同，因为它们共享同一个协方差矩阵，但是它们的均值不同</li>
</ul></li>
<li>图中的直线表示决策边界：<span class="math inline">\(p(y=1|x) = 0.5\)</span>，在该边界的一侧，我们预测 <span class="math inline">\(y=1\)</span> 是最可能的输出，在另一侧，则预测 <span class="math inline">\(y=0\)</span></li>
</ul></li>
</ul>
<h2 id="高斯判别分析与逻辑回归">高斯判别分析与逻辑回归</h2>
<ul>
<li>高斯判别分析与逻辑回归之间有着有趣的关系
<ul>
<li><p>如果我们将 <span class="math inline">\(p(y=1 |x; \phi,\mu_0,\mu_1, \Sigma)\)</span>表示为 <span class="math inline">\(x\)</span> 的函数，可以得到： <span class="math display">\[
p(y=1 | x;\phi,\Sigma,\mu_0,\mu_1) = \frac 1 {1+\exp(-\theta^T x)}
\]</span></p>
<ul>
<li>这与逻辑回归的形式完全相同
<ul>
<li>但一般来说，对于相同的数据集两种算法会给出不同的边界，究竟哪一个更好呢？</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>如果 <span class="math inline">\(p(x| y)\)</span> 属于多元高斯分布（共享 <span class="math inline">\(\Sigma\)</span>），那么 <span class="math inline">\(p(y| x)\)</span> 一定是逻辑函数</strong>
<ul>
<li><strong>但是反之则不成立</strong></li>
</ul></li>
<li>上述结论表明高斯判别分析相较于逻辑回归提出了<strong>更强</strong>的假设
<ul>
<li>如果这些假设都是正确的，那么高斯判别分析得到的结果会更好，是更好的模型</li>
</ul></li>
<li>特别地，当 <span class="math inline">\(p(x|y)\)</span> 属于多元高斯分布（共享 <span class="math inline">\(\Sigma\)</span>），GDA 是<strong>渐近有效</strong>的
<ul>
<li>这说明在数据量比较有限的情况下，没有算法能比 GDA 的表现更好</li>
<li>因此，在这种情况下，GDA 相比逻辑回归是一个更好的算法
<ul>
<li>即使对于较少的训练集，也可以取得更好的效果</li>
</ul></li>
</ul></li>
<li>相反，因为进行了更弱的假设，所以逻辑回归有更好的<strong>鲁棒性</strong>
<ul>
<li>对于错误的模型假设不那么敏感</li>
<li>有很多不同的假设会导致 <span class="math inline">\(p(y| x)\)</span> 是逻辑函数的形式，比如泊松分布
<ul>
<li>但是如果我们对于这样的数据使用 GDA，那么结果会变得不可预测</li>
</ul></li>
</ul></li>
<li><strong>总结</strong>：
<ul>
<li>GDA 进行了更强的模型假设并且数据有效性更高（需要更少的数据来学习）
<ul>
<li>但其前提条件是模型假设正确或近似正确</li>
</ul></li>
<li>逻辑回归进行较弱的假设，对于模型假设偏离的鲁棒性更好
<ul>
<li>如果数据集实际上不是高斯分布，那么在数据有限的情况下，逻辑回归一般会表现得比 GDA 更好</li>
<li>因此，实际中使用逻辑回归的情况比 GDA 多得多</li>
</ul></li>
</ul></li>
</ul>
<h1 id="朴素贝叶斯算法">朴素贝叶斯算法</h1>
<ul>
<li>在高斯判别分析中，特征向量是连续的、实数值向量
<ul>
<li>现在我们要谈谈一个不同的生成学习算法，其中 <span class="math inline">\(x\)</span> 是离散的向量</li>
</ul></li>
<li>让我们以识别垃圾邮件为例，这类问题被称为<strong>文本分类</strong>问题
<ul>
<li>假设我们有一个训练集（已经标记好了是否为垃圾邮件的邮件集合），我们首先需要构建表示一封邮件的特征向量</li>
<li>我们通过如下方式表示特征向量：
<ul>
<li>其长度为词表的长度（词表为所有可能出现的词的集合，一般通过训练集生成）
<ul>
<li>如果这封邮件包含了第 i 个词，<span class="math inline">\(x_i = 1\)</span>，否则 <span class="math inline">\(x_i = 0\)</span></li>
</ul></li>
<li><p>下图为一个简单的例子：</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-080125.png" width="30%"></p></li>
</ul></li>
</ul></li>
<li>选择好特征向量后，我们需要来构建生成模型
<ul>
<li>但考虑到 <span class="math inline">\(x\)</span> 是一个高维向量，因此如果直接对 <span class="math inline">\(p(x|y)\)</span> 建模，那么会得到一个参数向量的维数极高的多项分布，使计算过于复杂</li>
</ul></li>
<li>因此，我们需要做一个强力的假设，假设给定 <span class="math inline">\(y\)</span> 时， 每一个 $x_i $ 是条件独立的
<ul>
<li>这个假设被称为<strong>朴素贝叶斯假设</strong>，其引出的算法被称为<strong>朴素贝叶斯分类器</strong>
<ul>
<li>注意是条件独立而不是独立，即仅在给定 <span class="math inline">\(y\)</span> 的情况下独立</li>
</ul></li>
</ul></li>
<li><p>现在我们有（以50000维度为例）： <span class="math display">\[
\begin{align*}
p(x_1,\ldots,x_{50000}\mid y) &amp;=  
p(x_1 | y) p(x_2 | y,x_1)p(x_3 | y,x_1,x_2)\cdots p(x_{50000} | y,x_1, \ldots, x_{49999})\\
&amp;=p(x_1 | y)p(x_2 | y) p(x_3 | y)\cdot p(x_{50000} | y)\\
&amp;= \prod_{j=1}^np(x_j| y)
\end{align*}
\]</span></p>
<ul>
<li>第一个等式来自于概率的基本性质</li>
<li>第二个等式则使用了朴素贝叶斯假设
<ul>
<li>即使这个假设在现实中不一定成立，但其实际的效果还是不错的</li>
</ul></li>
</ul></li>
<li><p>模型包含了以下三个参数： <span class="math display">\[
\begin{align*}
\phi_{i|y=1} &amp;= p(x_i = 1 | y=1) \\
\phi_{i|y=0} &amp;= p(x_i = 1 | y=0) \\
\phi_y &amp;= p(y = 1 )
\end{align*}
\]</span></p></li>
<li><p>和之前一样，给定一个训练集 <span class="math inline">\(\{(x^{(i)},y^{(i)}); i=1,\dots,m\}\)</span>，我们可以写出如下的联合似然函数 <span class="math display">\[
\mathcal{L} (\phi_y,\phi_{i|y=0},\phi_{i|y=1}) = \prod_{i=1}^m p(x^{(i)},y^{(i)})
\]</span></p>
<ul>
<li><p>对这个联合似然函数进行最大似然分析，得到的参数值如下： <span class="math display">\[
\begin{align*}
\phi_{j|y=1} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=1\}}{\sum_{i=1}^m 1\{y^{(i)}=1\}}\\
\phi_{j|y=0} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=0\}}{\sum_{i=1}^m 1\{y^{(i)}=0\}} \\
\phi_y &amp;= \frac {\sum_{i=1}^m 1\{y^{(i)} = 1\}}{m}
\end{align*}
\]</span></p>
<ul>
<li>这些结果的得出是很自然的，从概率的角度也可以很好地解释</li>
</ul></li>
</ul></li>
<li><p>得到了这些参数之后，为了对一个新的输入 <span class="math inline">\(x\)</span> 进行预测，我们可以计算： <span class="math display">\[
\begin{align*}
p(y=1 | x) &amp;= \frac{p(x| y=1)p(y=1)}{p(x)} \\
&amp;= \frac {(\prod_{i=1}^n p(x_i | y=1))p(y=1)}{(\prod_{i=1}^n p(x_i | y=1))p(y=1)+(\prod_{i=1}^n p(x_i \mid y=0))p(y=0)}
\end{align*}
\]</span></p>
<ul>
<li>然后选择具有更高后验概率的类作为输出</li>
<li>这里的 <span class="math inline">\(n\)</span> 指字典的维数，需要先把 <span class="math inline">\(x\)</span> 转换为统一长度的向量</li>
</ul></li>
<li>在之前的例子中，输入的每一维特征都是是二元的，其对应的分布是伯努利分布
<ul>
<li>而当特征是多元时，其对应的分布应该用多项式分布建模</li>
<li><p>实际上，即便一些原始的输入数据是连续值，我们可以通过一个映射表将连续值映射为离散值，然后运用朴素贝叶斯方法进行建模</p>
<p><img src="http://media.zjubiomedit.com/2019-05-11-081704.png" width="60%"></p>
<ul>
<li>当原始，连续值的数据不能很好的用多元正态分布进行建模时，将其离散化再使用朴素贝叶斯建模往往会取得更好的效果</li>
</ul></li>
</ul></li>
</ul>
<h2 id="拉普拉斯平滑">拉普拉斯平滑</h2>
<ul>
<li>朴素贝叶斯算法有很多的应用，但是其当前的形式仍存在一个问题</li>
<li><p>在垃圾邮件分类问题中，如果词典中存在一个词，而这个词在训练集中从未出现过时，其最大似然分析得出的参数 <span class="math inline">\(\phi_{35000|y}\)</span> 将会是： <span class="math display">\[
\begin{align*}
\phi_{35000|y=1} &amp;= \frac{\sum_{i=1}^m 1\{x_{35000}^{(i)}=1 \wedge y^{(i)}=1\}}{\sum_{i=1}^m 1\{y^{(i)}=1\}} =0 \\
\phi_{35000|y=0} &amp;= \frac{\sum_{i=1}^m 1\{x_{35000}^{(i)}=1 \wedge y^{(i)}=0\}}{\sum_{i=1}^m 1\{y^{(i)}=0\}} = 0 \\
\end{align*}
\]</span></p>
<ul>
<li><p>因此，当我们尝试去预测含有该词的邮件是否为垃圾邮件时，后验概率的计算结果将变为： <span class="math display">\[
\begin{align*}
p(y=1 | x) &amp;= \frac {(\prod_{i=1}^n p(x_i | y=1))p(y=1)}{(\prod_{i=1}^n p(x_i \mid y=1))p(y=1)+(\prod_{i=1}^n p(x_i | y=0))p(y=0)} \\
&amp;= \frac 0 0
\end{align*}
\]</span></p>
<ul>
<li>这会导致我们无法进行预测</li>
<li>更一般的来看，如果你在有限的训练集上没有看到过某个事件，就认为其发生的概率为0，这在统计学上是不合理的</li>
</ul></li>
</ul></li>
<li><p>现在假设我们要分析一个多项式随机变量 <span class="math inline">\(z\)</span> 的均值，取值为 <span class="math inline">\(\{1,\dots,k\}\)</span>，我们可以分析 <span class="math inline">\(\phi_i=p(z=i)\)</span></p>
<ul>
<li><p>给定一个独立的观察集 <span class="math inline">\(\{z^{(1)},\dots,z^{(m)}\}\)</span>，最大似然估计的结果为： <span class="math display">\[
\phi_j = \frac {\sum_{i=1}^m 1\{z^{(i)}=j\}}{m}
\]</span></p>
<ul>
<li>如果我们用这个公式来进行最大似然估计，那么有一些 <span class="math inline">\(\phi_j\)</span> 的值可能为0（如果未在观察集中出现）</li>
<li><p>为了避免这个问题，我们可以使用<strong>拉普拉斯平滑</strong>，其形式为： <span class="math display">\[
\phi_j = \frac {\sum_{i=1}^m 1\{z^{(i)}=j\}+1}{m+k}
\]</span></p>
<ul>
<li>分子加 <span class="math inline">\(1\)</span>，分母加 <span class="math inline">\(k\)</span>，这样可以保证 <span class="math inline">\(\sum_{j=1}^m \phi_j=1\)</span>（概率之和为1）
<ul>
<li>同时保证了对所有的取值， <span class="math inline">\(\phi_j \neq 0\)</span>，从而解决了之前的问题</li>
</ul></li>
<li>实验证明，在大部分情况下，拉普拉斯平滑可以给出一个最优的估计</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>对于朴素贝叶斯分类器，使用拉普拉斯平滑，可以得到如下公式： <span class="math display">\[
\begin{align*}
\phi_{j|y=1} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=1\}+1}{\sum_{i=1}^m 1\{y^{(i)}=1\}+2}\\
\phi_{j|y=0} &amp;= \frac{\sum_{i=1}^m 1\{x_j^{(i)}=1 \wedge y^{(i)}=0\}+1}{\sum_{i=1}^m 1\{y^{(i)}=0\}+2} 
\end{align*}
\]</span></p>
<ul>
<li>因为x的取值有两种，所以分子加 <span class="math inline">\(1\)</span>，分母加 <span class="math inline">\(2\)</span></li>
<li>在实际中，一般不需要对 <span class="math inline">\(\phi_y\)</span> 进行拉普拉斯平滑</li>
</ul></li>
</ul>
<h2 id="文本分类的事件模型">文本分类的事件模型</h2>
<ul>
<li>让我们再探讨一个专门用于文本分类的模型来结束生成学习算法
<ul>
<li>虽然朴素贝叶斯对许多分类问题有很好的效果，但是对于文本分类，还有存在着一个效果更棒的相关模型</li>
</ul></li>
<li>在文本分类领域，之前我们使用的朴素贝叶斯模型被称为<strong>多元伯努利事件模型</strong>
<ul>
<li>现在我们将使用一个不同的模型，叫作<strong>多项式事件模型</strong></li>
</ul></li>
<li>我们将使用与之前不同的方式来表示一封邮件
<ul>
<li>令 <span class="math inline">\(x_i\)</span> 表示邮件中的第 <span class="math inline">\(i\)</span> 个词语，则其取值范围为 <span class="math inline">\(\{1,\ldots,|V|\}\)</span>
<ul>
<li><span class="math inline">\(|V|\)</span> 是词表（词典）的大小</li>
</ul></li>
<li>一封含有 <span class="math inline">\(n\)</span> 个词语的邮件现在将被表示为一个长度为 <span class="math inline">\(n\)</span> 的向量 <span class="math inline">\((x_1,x_2,\ldots,x_n)\)</span>
<ul>
<li>注意 <span class="math inline">\(n\)</span> 会随邮件的不同而变化</li>
</ul></li>
</ul></li>
<li><p>该模型的参数为： <span class="math display">\[
\begin{align*}
\phi_{i|y=1} &amp;= p(x_j = i | y=1)\\
\phi_{i|y=0} &amp;= p(x_j = i | y=0)\\
\phi_y &amp;= p(y)
\end{align*}
\]</span></p>
<ul>
<li>我们假设 $p(x_j| y) $ 对所有的 <span class="math inline">\(j\)</span>（邮件中词语的位置）都是一样的</li>
</ul></li>
<li>如果给定一个训练集 <span class="math inline">\(\{(x^{(i)},y^{(i)}); i=1,\ldots,m\}\)</span>，其中 <span class="math inline">\(x^{(i)} = (x_1^{(i)},x_2^{(i)},\dots,x_{n_i}^{(i)})\)</span>
<ul>
<li><p>这里 <span class="math inline">\(n_i\)</span> 表示第 <span class="math inline">\(i\)</span> 个训练样本的词数，那么数据的似然函数可以表示为： <span class="math display">\[
\begin{align*}
\mathcal{L} (\phi_y,\phi_{i|y=0},\phi_{i|y=1}) &amp;= \prod_{i=1}^m p(x^{(i)},y^{(i)}) \\
&amp;= \prod_{i=1}^m \left(\prod_{j=1}^{n_i} p(x_j^{(i)}\mid y;\phi_{i|y=0},\phi_{i|y=1}) \right) p(y^{(i)};\phi_y)
\end{align*}
\]</span></p></li>
<li><p>最大似然估计得出的结果如下： <span class="math display">\[
\begin{align*}
\phi_{k|y=1} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i}1\{x_j^{(i)}=k \wedge y^{(i)}=1\}}{\sum_{i=1}^m 1\{y^{(i)}=1\}n_i} \\
\phi_{k|y=0} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i} 1\{x_j^{(i)}=k \wedge y^{(i)}=0\}}{\sum_{i=1}^m 1\{y^{(i)}=0\}n_i} \\
\phi_y &amp;= \frac {\sum_{i=1}^m 1\{y^{(i)} = 1\}}{m}
\end{align*}
\]</span></p>
<ul>
<li>可以看到，这里在考虑字典中索引为 <span class="math inline">\(k\)</span> 的词时，会把在每个文本中出现的次数相加
<ul>
<li>所以该模型相比于之前的模型，不仅仅考虑是否出现，还考虑了出现的次数</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>如果有要应用拉普拉斯平滑，可以在分子加 <span class="math inline">\(1\)</span>，分母加 <span class="math inline">\(|V|\)</span>，得到： <span class="math display">\[
\begin{align*}
\phi_{k|y=1} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i}1\{x_j^{(i)}=k \wedge y^{(i)}=1\}+1}{\sum_{i=1}^m 1\{y^{(i)}=1\}n_i+|V|} \\
\phi_{k|y=0} &amp;= \frac{\sum_{i=1}^m\sum_{j=1}^{n_i} 1\{x_j^{(i)}=k \wedge y^{(i)}=0\}+1}{\sum_{i=1}^m 1\{y^{(i)}=0\}n_i+|V|} 
\end{align*}
\]</span></p></li>
<li><p>虽然朴素贝叶斯不是最好的分类算法，但因为其易于实现，所以非常适合作为你的第一个尝试</p></li>
</ul>
<h1 id="思维导图">思维导图</h1>
<p><img src="http://media.zjubiomedit.com/2019-05-11-085604.png" width="100%"></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    
      <div>
        



  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Zheyu Wang</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    
    <a href="https://xxwywzy.github.io/2018/03/22/CS229-4/" title="CS229学习笔记之四：生成学习算法">https://xxwywzy.github.io/2018/03/22/CS229-4/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CS229/" rel="tag"># CS229</a>
          
            <a href="/tags/生成学习算法/" rel="tag"># 生成学习算法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/18/CS229-3/" rel="next" title="CS229学习笔记之三：广义线性模型">
                <i class="fa fa-chevron-left"></i> CS229学习笔记之三：广义线性模型
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/04/01/CS229-5/" rel="prev" title="CS229学习笔记之五：支持向量机">
                CS229学习笔记之五：支持向量机 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="Zheyu Wang"/>
            
              <p class="site-author-name" itemprop="name">Zheyu Wang</p>
              <p class="site-description motion-element" itemprop="description">相信过程</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">50</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">20</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/xxwywzy" title="GitHub &rarr; https://github.com/xxwywzy" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://twitter.com/xxwywzy" title="Twitter &rarr; https://twitter.com/xxwywzy" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="http://weibo.com/xxwywzy" title="Weibo &rarr; http://weibo.com/xxwywzy" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://instagram.com/xxwywzy" title="Instagram &rarr; https://instagram.com/xxwywzy" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#算法概述"><span class="nav-number">1.</span> <span class="nav-text">算法概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#高斯判别分析"><span class="nav-number">2.</span> <span class="nav-text">高斯判别分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多元正态分布"><span class="nav-number">2.1.</span> <span class="nav-text">多元正态分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高斯判别分析模型"><span class="nav-number">2.2.</span> <span class="nav-text">高斯判别分析模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高斯判别分析与逻辑回归"><span class="nav-number">2.3.</span> <span class="nav-text">高斯判别分析与逻辑回归</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#朴素贝叶斯算法"><span class="nav-number">3.</span> <span class="nav-text">朴素贝叶斯算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#拉普拉斯平滑"><span class="nav-number">3.1.</span> <span class="nav-text">拉普拉斯平滑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#文本分类的事件模型"><span class="nav-number">3.2.</span> <span class="nav-text">文本分类的事件模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#思维导图"><span class="nav-number">4.</span> <span class="nav-text">思维导图</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zheyu Wang</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.5.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>




  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>



  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'FDq9lQI6SeKwqcOLjtAnvkN1-gzGzoHsz',
    appKey: 'IxP5URFEhxow4TfWyVNiowbH',
    placeholder: '请在这里评论=￣ω￣=',
    avatar: 'retro',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false
  });
</script>




  


  





  
  
  <script>
    
    function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .fail(function ({ responseJSON }) {
                console.log(`Failed to save Visitor num, with error message: ${responseJSON.error}`);
              })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1 }))
                .done(function() {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function() {
                  console.log('Failed to create');
                });
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log(`LeanCloud Counter Error: ${responseJSON.code} ${responseJSON.error}`);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'FDq9lQI6SeKwqcOLjtAnvkN1-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'FDq9lQI6SeKwqcOLjtAnvkN1-gzGzoHsz',
                'X-LC-Key': 'IxP5URFEhxow4TfWyVNiowbH',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            addCount(Counter);
          
        });
    });
  </script>



  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: "AMS"
      }
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
  overflow: auto hidden;
}
</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

</body>
</html>
