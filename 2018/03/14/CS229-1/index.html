<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/resources/favicon/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/resources/favicon/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/resources/favicon/favicon.png">
  <link rel="mask-icon" href="/resources/favicon/favicon.png" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xxwywzy.github.io","root":"/","images":"/resources/img/","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"livere","storage":true,"lazyload":false,"nav":null,"activeClass":"livere"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本篇博客为 CS229 学习笔记第一部分，主题是：线性回归。">
<meta property="og:type" content="article">
<meta property="og:title" content="CS229 学习笔记之一：线性回归">
<meta property="og:url" content="https://xxwywzy.github.io/2018/03/14/CS229-1/">
<meta property="og:site_name" content="口仆">
<meta property="og:description" content="本篇博客为 CS229 学习笔记第一部分，主题是：线性回归。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-02-05-060331.png">
<meta property="og:image" content="http://media.zjubiomedit.com/2019-02-05-062839.png">
<meta property="article:published_time" content="2018-03-14T14:06:32.000Z">
<meta property="article:modified_time" content="2023-08-21T06:43:23.000Z">
<meta property="article:author" content="Zheyu Wang">
<meta property="article:tag" content="CS229">
<meta property="article:tag" content="线性回归">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://media.zjubiomedit.com/2019-02-05-060331.png">


<link rel="canonical" href="https://xxwywzy.github.io/2018/03/14/CS229-1/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://xxwywzy.github.io/2018/03/14/CS229-1/","path":"2018/03/14/CS229-1/","title":"CS229 学习笔记之一：线性回归"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CS229 学习笔记之一：线性回归 | 口仆</title>
  











<link rel="stylesheet" href="/resources/fonts/longcang/longcang-regular.css" >
<link rel="stylesheet" href="/resources/fonts/lxgw/lxgwwenkailite-regular.css" >
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">口仆</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Long may the sunshine</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-culture"><a href="/culture/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>MEME</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">算法简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">求解方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.1.</span> <span class="nav-text">梯度下降</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB"><span class="nav-number">2.1.1.</span> <span class="nav-text">分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%96%B9%E5%90%91%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-number">2.1.2.</span> <span class="nav-text">梯度方向的选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="nav-number">2.2.</span> <span class="nav-text">正规方程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%AF%BC%E6%95%B0"><span class="nav-number">2.2.1.</span> <span class="nav-text">矩阵导数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%87%8D%E7%8E%B0"><span class="nav-number">2.2.1.1.</span> <span class="nav-text">2.2.2 最小二乘重现</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E8%A7%A3%E9%87%8A"><span class="nav-number">3.</span> <span class="nav-text">概率解释</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">概率模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.</span> <span class="nav-text">似然函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E5%8A%A0%E6%9D%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">4.</span> <span class="nav-text">局部加权线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AC%A0%E6%8B%9F%E5%90%88%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-number">4.1.</span> <span class="nav-text">欠拟合与过拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%80%9D%E8%B7%AF"><span class="nav-number">4.2.</span> <span class="nav-text">算法思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%9D%9E%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0"><span class="nav-number">4.3.</span> <span class="nav-text">参数学习与非参数学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE"><span class="nav-number">5.</span> <span class="nav-text">思维导图</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zheyu Wang"
      src="/resources/favicon/avatar.png">
  <p class="site-author-name" itemprop="name">Zheyu Wang</p>
  <div class="site-description" itemprop="description">相信过程</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">85</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/xxwywzy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/xxwywzy" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/xxwywzy" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/xxwywzy" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;xxwywzy" rel="noopener me" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xxwywzy.github.io/2018/03/14/CS229-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/resources/favicon/avatar.png">
      <meta itemprop="name" content="Zheyu Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="口仆">
      <meta itemprop="description" content="相信过程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CS229 学习笔记之一：线性回归 | 口仆">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS229 学习笔记之一：线性回归
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-03-14 22:06:32" itemprop="dateCreated datePublished" datetime="2018-03-14T22:06:32+08:00">2018-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">课程笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><div class="note info"><p>本篇博客为 CS229 学习笔记第一部分，主题是：线性回归。</p>
</div>
<span id="more"></span>
<h1 id="算法简介">算法简介</h1>
<p>线性回归是⼀种<strong>监督学习</strong>算法，即给定⼀个训练集，去学习⼀个假设函数，⽤来尽量精确地预测每个样本对应的输出。从输出变量的离散程度来看，监督学习算法可以分为两类。线性回归属于回归算法，其输出变量<strong>连续</strong>；而另⼀类监督学习算法是分类算法，其输出变量离散。</p>
<p>线性回归的假设函数为： <span class="math display">\[
h_\theta(x) = \sum_{i=0}^n\theta_ix_i = \theta^Tx
\]</span> 线性回归的代价函数为： <span class="math display">\[
J(\theta) = \frac 1 2 \sum_{i=1}^m \left(h_\theta(x^{(i)})-y^{(i)}\right)^2
\]</span> 线性回归的学习目标：通过训练集找出使代价函数最小的一组参数 <span class="math inline">\(\theta\)</span>（又称最小二乘法）。</p>
<h1 id="求解方法">求解方法</h1>
<p>对于线性回归代价函数的求解，有两种可选方法：<strong>梯度下降</strong>与<strong>正规方程</strong>。</p>
<h2 id="梯度下降">梯度下降</h2>
<p>梯度下降是⼀种求解最优化问题的迭代方法，具体步骤为：</p>
<ol type="1">
<li>随机选取初始的 <span class="math inline">\(\theta\)</span></li>
<li>不断地以梯度的方向修正 <span class="math inline">\(\theta\)</span></li>
<li>最终使 <span class="math inline">\(J(\theta)\)</span> 收敛至局部最优（在最小二乘中，局部最优即全局最优） <span class="math display">\[
\theta_j := \theta_j-\alpha\frac{\partial}{\partial \theta_j}J(\theta)
\]</span></li>
</ol>
<p><span class="math inline">\(\alpha\)</span> 称为学习速率，太小会导致收敛缓慢，太大会导致错过最优点，需要谨慎选择。</p>
<p>对公式进一步推导（假设只有一个样本点），得到： <span class="math display">\[
\begin{align*}
\frac{\partial}{\partial \theta_j}J(\theta) &amp;=\frac{\partial}{\partial \theta_j}\frac 1 2(h_\theta(x)-y)^2 \\&amp;=2\cdot\frac1 2(h_\theta(x)-y)\cdot\frac{\partial}{\partial \theta_j}(h_\theta(x)-y) \\&amp;=(h_\theta(x)-y)\cdot\frac{\partial}{\partial \theta_j}\left(\sum_{i=0}^n\theta_ix_i-y\right) \\&amp;=(h_\theta(x)-y)x_j
\end{align*}
\]</span> 将上述结果代回公式得到： <span class="math display">\[
\theta_j := \theta_j+\alpha\left(y^{(i)}-h_\theta(x^{(i)})\right)x^{(i)}_j
\]</span> 注意公式中通过数学变换将减号变成了加号， 方便之后与逻辑回归的结果作比较。</p>
<h3 id="分类">分类</h3>
<p>梯度下降主要可以分为两类：<strong>批量梯度下降</strong>和<strong>随机梯度下降</strong>：</p>
<ul>
<li>批量梯度下降：每次计算梯度都需要遍历所有的样本点，当样本量很大时， 计算速度会十分缓慢</li>
<li>随机梯度下降：每次只考虑⼀个样本点，而不是所有样本点，计算速度会提高， 但是收敛过程会比较曲折， 可能无法精确收敛至最优值</li>
</ul>
<p>随机梯度下降的一种优化形式是<strong>小批量梯度下降</strong>，利用矩阵并行运算，一次处理小批量的样本点，有时可以比随机梯度下降速度更快。</p>
<h3 id="梯度方向的选择">梯度方向的选择</h3>
<p>选择梯度⽅向的原因是它是使代价函数减小（下降）最大的方向，我们可以利用柯西不等式对这一结论进行证明：</p>
<p>当 <span class="math inline">\(\theta\)</span> 改变一个很小的量时，利用泰勒公式，忽略一阶导数之后的项，得： <span class="math display">\[
\Delta J \thickapprox \frac{\partial J}{\partial \theta_0} \Delta \theta_0+ \frac{\partial J}{\partial \theta_1} \Delta \theta_1+\cdots+ \frac{\partial J}{\partial \theta_n} \Delta \theta_n
\]</span> 定义如下变量： <span class="math display">\[
\begin{split}
\Delta\theta &amp;\equiv (\Delta\theta_0,\Delta\theta_1,\ldots,\Delta\theta_n)^T \\
\nabla J &amp;\equiv (\frac{\partial J}{\partial \theta_0},\frac{\partial J}{\partial \theta_1},\ldots,\frac{\partial J}{\partial \theta_n})^T
\end{split}
\]</span> 将其代回上式，得： <span class="math display">\[
\Delta J \thickapprox \nabla J\cdot\Delta \theta
\]</span> 根据柯西不等式，有（等号当且仅当 <span class="math inline">\(\Delta \theta\)</span> 与 <span class="math inline">\(\nabla J\)</span> 线性相关时成立）： <span class="math display">\[
\lvert\Delta J \rvert\,\thickapprox \,\lvert\nabla J\cdot\Delta \theta \rvert\,\le\,\|\nabla J\|\cdot\|\Delta \theta \|
\]</span> 因此，要使 <span class="math inline">\(\Delta J\)</span> 最小，即 <span class="math inline">\(\mid\Delta J \mid\)</span> 最大且 <span class="math inline">\(\Delta J&lt;0\)</span>，而当且仅当 <span class="math inline">\(\Delta \theta = -\alpha \nabla J \quad(\alpha&gt;0)\)</span> 时满足条件，即沿着梯度方向调整 <span class="math inline">\(\theta\)</span>.</p>
<h2 id="正规方程">正规方程</h2>
<p>我们可以通过<strong>正规方程</strong>直接求出 <span class="math inline">\(\theta\)</span> 的解析解。推导过程如下：</p>
<h3 id="矩阵导数">矩阵导数</h3>
<p>对一个将 <span class="math inline">\(m\times n\)</span> 的矩阵映射至实数的函数，定义其导数为： <span class="math display">\[
\nabla_A f(A) = \left[
\begin{matrix}
 \frac{\partial f}{\partial A_{11}}     &amp; \cdots &amp; \frac{\partial f}{\partial A_{1n}}      \\
 \vdots  &amp; \ddots &amp; \vdots \\
  \frac{\partial f}{\partial A_{m1}}     &amp; \cdots &amp; \frac{\partial f}{\partial A_{mn}}     \\
\end{matrix}
\right]
\]</span> 对一个 <span class="math inline">\(n\times n\)</span> 方阵，它的<strong>迹</strong>定义为<strong>对角线元素之和</strong>： <span class="math display">\[
\text{tr}\,A = \sum_{i=1}^nA_{ii}
\]</span> 易证明迹操作具有如下性质（各矩阵为⽅阵）： <span class="math display">\[
\mbox{tr}\,AB = \mbox{tr}\,BA,\\
\mbox{tr}\,ABC = \mbox{tr}\,CAB = \mbox{tr}\,BCA,\\
\mbox{tr}\,ABCD = \mbox{tr}\,DABC = \mbox{tr}\,CDAB = \mbox{tr}\,BCDA
\]</span> 同样易证明如下性质（<span class="math inline">\(a\)</span> 为实数）： <span class="math display">\[
\mbox{tr}\,A = \mbox{tr}\,A^T\\
\mbox{tr}\,(A+B) = \mbox{tr}\,A+ \mbox{tr}\,B\\
\mbox{tr}\,aA = a\,\mbox{tr}\,A
\]</span> 基于以上定义，可以证明一些关于矩阵导数的性质（最后一个等式只针对非奇异矩阵）： <span class="math display">\[
\begin{eqnarray*}
\nabla_A\mbox{tr}\,AB &amp;=&amp; B^T \\
\nabla_{A^T}f(A) &amp;=&amp; (\nabla_{A}f(A))^T \\
\nabla_A\mbox{tr}\,ABA^TC &amp;=&amp; CAB+C^TAB^T  \\
\nabla_A\lvert A \rvert &amp;=&amp; \lvert A \rvert(A^{-1})^T
\end{eqnarray*}
\]</span></p>
<h4 id="最小二乘重现">2.2.2 最小二乘重现</h4>
<p>对于训练集，可以写成如下的形式： <span class="math display">\[
X = \left[
\begin{matrix}
 —(x^{(1)})^T—  \\ 
  —(x^{(2)})^T—   \\
 \vdots   \\
  —(x^{(m)})^T— \\
\end{matrix}
\right], \; \vec y=\left[
\begin{matrix}
 y^{(1)}  \\ 
  y^{(2)}   \\
 \vdots   \\
  y^{(m)} \\
\end{matrix}
\right]
\]</span> 因为 <span class="math inline">\(h_{\theta}(x^{(i)}) = (x^{(i)})^T\theta\)</span>，我们可以得出： <span class="math display">\[
\begin{align*}
 X\theta-\vec y&amp;=\left[
\begin{matrix}
 (x^{(1)})^T\theta  \\ 
  (x^{(2)})^T\theta   \\
 \vdots   \\
  (x^{(m)})^T\theta \\
\end{matrix}
\right]-\left[
\begin{matrix}
 y^{(1)}  \\ 
  y^{(2)}   \\
 \vdots   \\
  y^{(m)} \\
\end{matrix}
\right] \\
&amp;=\left[
\begin{matrix}
 h_{\theta}(x^{(1)})-y^{(1)}  \\ 
  h_{\theta}(x^{(2)})-y^{(2)}   \\
 \vdots   \\
  h_{\theta}(x^{(m)})-y^{(m)} \\
\end{matrix}
\right] 
 \end{align*}
\]</span> 此外，对于一个向量z，我们有 <span class="math inline">\(z^Tz = \sum_iz_i^2\)</span>，因此综上可以得出： <span class="math display">\[
\begin{align*}
 \frac 1 2(X\theta-\vec y)^T(X\theta-\vec y) &amp;= \frac 1 2 \sum_{i=1}^m \left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\
 &amp;= J(\theta)
  \end{align*}
\]</span> 所以为了使 <span class="math inline">\(J(\theta)\)</span> 最小，即只需找出其导数为 0 时 <span class="math inline">\(\theta\)</span> 的值。下面给出详细的求解过程：</p>
<p>首先，基于矩阵导数的性质，进行如下推导： <span class="math display">\[
\begin{eqnarray*}
\nabla_{A^T}f(A) &amp;=&amp; (\nabla_{A}f(A))^T\\
\nabla_A\mbox{tr}\,ABA^TC &amp;=&amp; CAB+C^TAB^T  \\
\nabla_{A^T}\mbox{tr}\,ABA^TC &amp;=&amp;  (CAB+C^TAB^T)^T\\
&amp;=&amp; (CAB)^T+(C^TAB^T)^T \\
&amp;=&amp; B^TA^TC^T+BA^TC
\end{eqnarray*}
\]</span></p>
<p>其中最后两步的推导基于矩阵转置的下列性质： <span class="math display">\[
(A+B)^T=A^T+B^T \\
(AB)^T=B^TA^T
\]</span> 基于以上所述，有： <span class="math display">\[
\begin{align*}
\nabla_\theta J(\theta) &amp;= \nabla  \frac 1 2(X\theta-\vec y)^T(X\theta-\vec y) \\
&amp;= \frac 1 2 \nabla_\theta(\theta^TX^T-\vec y^T)(X\theta-\vec y)\\
&amp;= \frac 1 2 \nabla_\theta\underbrace{(\theta^TX^TX\theta-\theta^TX^T\vec y-\vec y^TX\theta+\vec y^T\vec y)}_{a = \text {tr}\,a,\,a\in R}\\
&amp;= \frac 1 2 \nabla_\theta\underbrace{\text{tr}\,(\theta^TX^TX\theta-\theta^TX^T\vec y-\vec y^TX\theta+\vec y^T\vec y)}_{ \text {tr}\,(A+B)=\text {tr}\,A+\text {tr}\,B}\\
&amp;= \frac 1 2 \nabla_\theta\underbrace{(\text {tr}\,\theta^TX^TX\theta-\text {tr}\,\theta^TX^T\vec y-\text {tr}\,\vec y^TX\theta+\text {tr}\,\vec y^T\vec y)}_{\text{tr}\,A = \text{tr}\,A^T}\\
&amp;= \frac 1 2 \nabla_\theta(\text {tr}\,\theta^TX^TX\theta-2\text {tr}\,\vec y^TX\theta+\underbrace{\text {tr}\,\vec y^T\vec y}_{\text{don&#39;t depend on }\theta})\\
&amp;= \frac 1 2 \nabla_\theta(\text {tr}\,\theta^TX^TX\theta-2\text {tr}\,\vec y^TX\theta)\\
&amp;= \frac 1 2 (\underbrace{\nabla_\theta\text {tr}\,\theta^TX^TX\theta}_{\text{use }(8),\,A^T=\theta,B=B^T=X^TX,C=I}-2\underbrace{\nabla_\theta\text {tr}\,\vec y^TX\theta}_{\text{tr}\,ABC = \text{tr}\,CAB,\text{then use }(4)})\\
&amp;= \frac 1 2(X^TX\theta+X^TX\theta-2X^T\vec y)\\
&amp;=X^TX\theta-X^T\vec y
\end{align*}
\]</span> 因此，正规方程如下： <span class="math display">\[
X^TX\theta=X^T\vec y\\
\theta=(X^TX)^{-1}X^T\vec y
\]</span></p>
<p>注意：不可逆问题可以通过伪逆计算或正则化处理解决。</p>
<h1 id="概率解释">概率解释</h1>
<p>在线性回归中，为什么要选择最小二乘函数作为代价函数？我们可以用<strong>概率模型</strong>来对其进行解释。</p>
<h2 id="概率模型">概率模型</h2>
<p>假设真实值与输入之间满足如下等式： <span class="math display">\[
y^{(i)} = \theta^Tx^{(i)}+\epsilon^{(i)}
\]</span></p>
<p>其中 <span class="math inline">\(\epsilon^{(i)}\)</span> 是误差项，表示没有被建模的因素或是随机噪声。</p>
<p>进一步假设误差项是独立同分布的，那么根据中心极限定理，大量相互独立的随机变量符合以 0 为中心的正态分布（可以理解为大量独立随机变量的大部分误差会相互抵消），即 <span class="math inline">\(\epsilon^{(i)}\sim {\cal N} (0,\sigma^2)\)</span>，那么有： <span class="math display">\[
p(\epsilon^{(i)}) = \frac{1}{\sqrt{2\pi}\sigma}\text{exp}\left(-\frac{(\epsilon^{(i)})^2}{2\sigma^2}\right)
\]</span> 而误差的概率和预测出真实值的概率是一样的，因此： <span class="math display">\[
p(y^{(i)} \,\rvert \,x^{(i)};\theta ) = \frac{1}{\sqrt{2\pi}\sigma}\text{exp}\left(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\right)
\]</span></p>
<p>注意，这里 <span class="math inline">\(p(y^{(i)} \,\rvert \,x^{(i)};\theta )\)</span> 不同于 <span class="math inline">\(p(y^{(i)} \,\rvert \,x^{(i)},\theta )\)</span>，这里指给定 <span class="math inline">\(x^{(i)}\)</span>，以 <span class="math inline">\(\theta\)</span> 为参数的 <span class="math inline">\(y^{(i)}\)</span> 的分布，因为对于训练集，<span class="math inline">\(\theta\)</span> 是客观存在的，只是当前还不确定。（这是一种频率学派的观点，之后会细说）</p>
<p>因此，我们得出真实值是以预测值为中心的一个正态分布： <span class="math display">\[
y^{(i)} \,\rvert \,x^{(i)};\theta\sim {\cal N }(\theta^Tx^{(i)},\sigma^2)
\]</span></p>
<h2 id="似然函数">似然函数</h2>
<p>给定训练集 <span class="math inline">\({X}\)</span> 和参数 <span class="math inline">\(\theta\)</span>，预测结果等于真实结果的概率，将其看作 <span class="math inline">\(\theta\)</span> 的函数，可以理解为 <span class="math inline">\(\theta\)</span> 为真实 <span class="math inline">\(\theta\)</span> 的可能性（似然性），即： <span class="math display">\[
L(\theta)=L(\theta;X,\vec y)=p(\vec y  \,\rvert\, X;\theta)
\]</span> 因为每个样本是独立同分布的，所以有： <span class="math display">\[
\begin{align*}
L(\theta) &amp;= \prod_{i=1}^m p(y^{(i)}\,\lvert\,x^{(i)};\theta)\\
&amp;=\prod_{i=1}^m  \frac{1}{\sqrt{2\pi}\sigma}\text{exp}\left(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\right)
\end{align*}
\]</span> 现在，我们可以通过<strong>最大似然法</strong>，即找出使 <span class="math inline">\(L(\theta)\)</span> 最大的那个 <span class="math inline">\(\theta\)</span>，作为对参数 <span class="math inline">\(\theta\)</span> 的最佳取值。</p>
<p>在实际应用中，为了简化计算，通常不直接求似然函数的最大值，而是采用<strong>对数似然</strong>函数： <span class="math display">\[
\begin{align*}
\ell(\theta) &amp;= \text{log}L(\theta)\\
&amp;= \text{log}\prod_{i=1}^m \frac{1}{\sqrt{2\pi}\sigma}\text{exp}\left(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\right)\\
&amp;= \sum_{i=1}^m\text{log}\frac{1}{\sqrt{2\pi}\sigma}\text{exp}\left(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\right)\\
&amp;=m\text{log}\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{\sigma^2} \cdot \frac 1 2 \sum_{i=1}^m(y^{(i)} - \theta^Tx^{(i)})^2
\end{align*}
\]</span> 因此，最大化 <span class="math inline">\(l(\theta)\)</span> 就是最小化： <span class="math display">\[
\frac 1 2 \sum_{i=1}^m(y^{(i)} - \theta^Tx^{(i)})^2
\]</span></p>
<p>这正是我们之前提出的<strong>最小二乘代价函数</strong>！从公式可以看出， <span class="math inline">\(\theta\)</span> 的选择并不依赖于 <span class="math inline">\(\sigma^2\)</span>。此外，概率解释只是对最小二乘法的一种合理解释，其实还有其他的解释方法。</p>
<h1 id="局部加权线性回归">局部加权线性回归</h1>
<p>本节将介绍⼀种特殊的线性回归算法：<strong>局部加权线性回归</strong>。</p>
<h2 id="欠拟合与过拟合">欠拟合与过拟合</h2>
<p>对于传统的线性回归，特征的选择极为重要，对于下面三幅图，我们称第一幅图的模型是<strong>欠拟合</strong>，第三幅图的模型则是<strong>过拟合</strong>（之后的笔记中会详细介绍）。</p>
<p><img src="http://media.zjubiomedit.com/2019-02-05-060331.png" width=75%></p>
<p>可以看出，找到一个全局的线性模型去拟合整个训练集，并不是一件简单的事情，往往会引起欠拟合或是过拟合的发生。对于这种情况之后会给出解决方案，而这里我们提出了另外一种思路，即<strong>局部线性加权回归</strong>，这种方案可以使特征的选择的重要性降低。</p>
<h2 id="算法思路">算法思路</h2>
<p>局部线性加权回归的思路是并不去拟合整个训练集来产生全局的模型，而是在每次预测时，只去拟合给定输入 <span class="math inline">\(x\)</span> 附近的一小段训练集，无论全局训练集是怎样的一条分布曲线，在局部小段数据上，都可以用线性去逼近。具体步骤如下： 1. 拟合 <span class="math inline">\(\theta\)</span> 来最小化 <span class="math inline">\(\sum_i\omega^{(i)}(y^{(i)} - \theta^Tx^{(i)})^2\)</span> 2. 输出 <span class="math inline">\(\theta^Tx\)</span></p>
<p>这里 <span class="math inline">\(\omega^{(i)}\)</span> 是<strong>非负权重</strong>，一般取值如下： <span class="math display">\[
\omega^{(i)}=exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)
\]</span></p>
<p>当 <span class="math inline">\(x\)</span> 为向量时表达式有所不同。可以看出，离给定输入越近的样本点权重越大，拟合程度越高。</p>
<p><span class="math inline">\(\omega^{(i)}\)</span> 的定义与高斯分布类似，但并没有关系，分布曲线同为钟型。<span class="math inline">\(\tau\)</span> 称为<strong>带宽参数</strong>，用来控制钟型曲线的顶峰下降速度，即权重变化的快慢，需要根据具体情况作出调整。</p>
<h2 id="参数学习与非参数学习">参数学习与非参数学习</h2>
<p>局部加权线性回归本质上是一种<strong>非参数学习算法</strong>，而传统的线性回归是一种<strong>参数学习算法</strong>。</p>
<p>两者的区别在于： + 参数学习算法有一组有限的、固定的参数，一旦完成拟合，只需要保存下参数值做预测，而不需要保存完整的训练集； + 非参数学习算法由于参数不固定，所以需要保存完整的训练集来进行预测，而不仅仅是保存参数。</p>
<p><strong>非参数学习</strong>导致的结果：为了表达假设 <span class="math inline">\(h\)</span> 而保存的数据将随着训练集的大小而线性增长。</p>
<h1 id="思维导图">思维导图</h1>
<p><img src="http://media.zjubiomedit.com/2019-02-05-062839.png" width=80%></p>

    </div>

    
    
    

    <footer class="post-footer">




<div class="license">
  <div class="license-title">CS229 学习笔记之一：线性回归</div>
  <div class="license-link">
    <a href="https://xxwywzy.github.io/2018/03/14/CS229-1/">https://xxwywzy.github.io/2018/03/14/CS229-1/</a>
  </div>
  <div class="license-meta">
    <div class="license-meta-item">
      <div class="license-meta-title">本文作者</div>
      <div class="license-meta-text">
          Zheyu Wang
      </div>
    </div>
      <div class="license-meta-item">
        <div class="license-meta-title">发布于</div>
        <div class="license-meta-text">
          2018-03-14
        </div>
      </div>
      <div class="license-meta-item">
        <div class="license-meta-title">更新于</div>
        <div class="license-meta-text">
          2023-08-21
        </div>
      </div>
    <div class="license-meta-item">
      <div class="license-meta-title">许可协议</div>
      <div class="license-meta-text">
          <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank">CC BY-NC-SA 4.0</a>
      </div>
    </div>
  </div>
  <div class="license-statement">
      转载或引用本文时，请遵守上述许可协议，注明出处、不得用于商业用途！
  </div>
</div>
          <div class="post-tags">
              <a href="/tags/CS229/" rel="tag"># CS229</a>
              <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag"># 线性回归</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2001/07/18/fc-story-1/" rel="prev" title="空之轨迹 FC 剧情小说 - 序幕">
                  <i class="fa fa-angle-left"></i> 空之轨迹 FC 剧情小说 - 序幕
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/03/15/CS229-2/" rel="next" title="CS229 学习笔记之二：分类与逻辑回归">
                  CS229 学习笔记之二：分类与逻辑回归 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="lv-container" data-id="city" data-uid="MTAyMC81ODgyNi8zNTI4OA=="></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Zheyu Wang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">332k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">18:26</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script src="/js/third-party/comments/livere.js"></script>



  <style>
    #taboola-livere { display: none;}
  </style>



<script type="text/javascript">
var linkLists = document.querySelectorAll(".link-list");

linkLists.forEach(function(linkList) {
  var listPath = linkList.getAttribute('json-src');
  var iconPath = linkList.getAttribute('icon-src');
  
  var xhr = new XMLHttpRequest();
  xhr.open('GET', listPath, true);
  xhr.onreadystatechange = function() {
    if (xhr.readyState === 4 && xhr.status === 200) {
      var data = JSON.parse(xhr.responseText);
      
      var li = "";
      linkList.innerHTML = '';

      for (var infoIndex = 0; infoIndex < data.length; infoIndex++) {
        var info = data[infoIndex];
        var labelWarn = info['warn'] ? '<span class="label warn">' + info['warn'] + '</span>' : '';
        var labelInfo = info['info'] ? '<span class="label info">' + info['info'] + '</span>' : '';

        li += '<div class="link-list-container">';
        li += '<img class="link-list-image" src="' + iconPath + info['logo'] + '">';
        li += '<p>' + info['title'] + labelInfo + labelWarn + '</p>';
        li += '<p>' + info['intro'] + '</p>';
        li += '<a href="' + info['url'] + '" rel="noopener" target="_blank" data-pjax-state=""></a>';
        li += '</div>';
      }
      
      linkList.innerHTML = li;
    }
  };
  xhr.send();
});
</script>


<script type="text/javascript">
var cultureList = document.querySelectorAll(".culture-list");
if (cultureList.length !== 0) {
  var j = -1;
  for (var i = 0; i < cultureList.length; i++) {
    const listPath = cultureList[i].getAttribute('json-src');
    const coverPath = cultureList[i].getAttribute('cover-src');
    
    var xhr = new XMLHttpRequest();
    xhr.open('GET', listPath, true);
    xhr.onreadystatechange = function () {
      if (xhr.readyState === 4 && xhr.status === 200) {
        j++;
        var data = JSON.parse(xhr.responseText);
        var li = "";
        
        cultureList[j].innerHTML = '';

        for (var infoIndex = 0; infoIndex < data.length; infoIndex++) {
          var info = data[infoIndex];
          
          var title = info['title'];
          if (info['link']) {
            title = '<a href="' + info['link'] + '">' + info['title'] + '</a>';
          }

          var author = info['author'] ? '<span class="author">' + info['author'] + '</span>' : '';

          var intro = info['intro'] ? info['intro'] : '';

          var star = '';
          if (info['score'] == null) {
            star = '';
          } else {
            var colorStar = '';
            var greyStar = '';
            var int = Math.floor(info['score']); //整数部分
            var fract = 0;
            if (info['score'] % 1 !== 0) {
              fract = 1;
            }
            for (var m = 0; m < int; m++) {
              colorStar += '★';
            }
            if (fract !== 0) {
              colorStar += '☆';
            }
            for (var m = 0; m < (5 - fract - int); m++) {
              greyStar += '☆';
            }
            if (info['score'] !== 5) {
              star = '<span class="star-score">' + colorStar + '<span class="grey-star">' + greyStar + '</span></span>';
            } else {
              star = '<span class="star-score">' + colorStar + '</span>';
            }
          }

          li += '<div class="media">';
          li += '<div class="media-cover" style="background-image:url(' + coverPath + info['cover'] + ')"></div>';
          li += '<div class="media-meta">';
          li += '<div class="media-meta-item title">' + title + '</div>';
          li += '<div class="media-meta-item">' + author + star + '</div>';
          li += '<div class="media-meta-item intro">' + intro + '</div>';
          li += '</div></div>';
        }
        
        cultureList[j].innerHTML = li;
      }
    };
    xhr.send();
  }
}
</script>




<script src="/resources/minigrid.min.js"></script>
<script type="text/javascript">
var album = document.querySelector(".album");
if (album) {
  // 相册列表 JSON 数据
  var imgDataPath = album.getAttribute('json-src');
  // 照片存储路径
  var imgPath = album.getAttribute('photo-src');
  // 最多显示数量
  var imgMaxNum = 50;
  // 获取窗口大小以决定图片宽度
  var windowWidth = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth;
  var imageWidth;

  if (windowWidth < 768) {
    imageWidth = 145; // 移动端图片宽度
  } else {
    imageWidth = 235;
  }

  // 腾讯云自定义样式 (数据万象外网流量需要付费)
  //var imgStyle = '!' + imageWidth + 'x';
  //var imgStyle = '!300x';

  // 生成相册
  var linkDataPath = imgDataPath;
  var photo = {
    page: 1,
    offset: imgMaxNum,
    init: function () {
      var that = this;
      var xhr = new XMLHttpRequest();
      xhr.open("GET", linkDataPath, true);
      xhr.onreadystatechange = function () {
        if (xhr.readyState === 4 && xhr.status === 200) {
          var data = JSON.parse(xhr.responseText);
          that.render(that.page, data);
        }
      };
      xhr.send();
    },
    render: function (page, data) {
      var begin = (page - 1) * this.offset;
      var end = page * this.offset;
      if (begin >= data.length) return;
      var imgNameWithPattern, imgName, imageSize, imageX, imageY, li = "";
      for (var i = begin; i < end && i < data.length; i++) {
        imgNameWithPattern = data[i].split(' ')[1];
        imgName = imgNameWithPattern.split('.')[0];
        imageSize = data[i].split(' ')[0];
        imageX = imageSize.split('.')[0];
        imageY = imageSize.split('.')[1];
        li += '<div class="card" style="width:' + imageWidth + 'px" >';
        li += '<div class="album-photo" style="height:'+ imageWidth * imageY / imageX + 'px">';
        li += '<a class="fancybox fancybox.image" href="' + imgPath + imgNameWithPattern + '" itemscope="" itemtype="http://schema.org/ImageObject" itemprop="url" data-fancybox="group" rel="group" data-caption="' + imgName + '" title="' +  imgName + '">';
        li += '<img data-src="' + imgPath + imgNameWithPattern + '" src="' + imgPath + imgNameWithPattern + '" alt="' +  imgName + '" data-loaded="true">';
        li += '</a>';
        li += '</div>';
        li += '</div>';
      }
      album.insertAdjacentHTML('beforeend', li);
      this.minigrid();
    },
    minigrid: function () {
      var grid = new Minigrid({
        container: '.album',
        item: '.card',
        gutter: 12
      });
      grid.mount();
      window.addEventListener('resize', function () {
        grid.mount();
      });
    }
  };
  photo.init();
}
</script>
</body>
</html>
